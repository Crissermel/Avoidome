{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from urllib import request\n",
    "from tqdm import tqdm\n",
    "import os, sys\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "class ProteinSequence:\n",
    "    \"\"\"\n",
    "    Simple object for storing protein info\n",
    "    \"\"\"\n",
    "    def __init__(self, sequence: str=None, protein_id: str=None, filename: str=None, info: str=None):\n",
    "        self.info = info\n",
    "        self.seq = sequence\n",
    "        self.protein_id = protein_id\n",
    "        self.len = None\n",
    "        self.ligand_idxs = [] # Datapoint line idxs in papyrus\n",
    "        self.n_ligands = 0  # Number of datapoints in papyrus\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Protein Seq: {self.protein_id}, length: \\\n",
    "                {len(self)}, ligands: {self.n_ligands}\"\n",
    "\n",
    "\n",
    "def get_names(target_proteins):\n",
    "    \"\"\"\n",
    "    Returns a dictionary of protein names for the target proteins (from Fasta headers)\n",
    "    \"\"\"\n",
    "    folder = '/home/andrius/datasets/foldedPapyrus/proteins'\n",
    "    proteins = [load_protein_sequence(pid, folder) for pid in target_proteins]\n",
    "    headers = [p.info for p in proteins]\n",
    "    name_strings = [h.split('|')[2].split('OS')[0] for h in headers]\n",
    "    tags = [n.split(' ')[0] for n in name_strings]\n",
    "    names = [' '.join([n.split(' ')[1:]]) for n in name_strings]\n",
    "    target_proteins.sort()\n",
    "    tag_dict  = OrderedDict(dict(zip(target_proteins, tags)))\n",
    "    name_dict = OrderedDict(dict(zip(target_proteins, names)))\n",
    "    \n",
    "    return name_dict, tag_dict\n",
    "\n",
    "#def download_fasta(protein_id, output_folder):\n",
    "#    \"\"\"\n",
    "#    Retrieves the fasta file from Uniprot based on protein ID\n",
    "#    \"\"\"\n",
    "#    try:\n",
    "#        # remote_url = f'https://uniprot.org/uniprot/{protein_id}.fasta'\n",
    "#        remote_url = f'https://rest.uniprot.org/uniprotkb/{protein_id}.fasta'\n",
    "#        local_file = f'{output_folder}/{protein_id}.fasta'\n",
    "#        # open(local_file, 'a').close()\n",
    "#        request.urlretrieve(remote_url, local_file)\n",
    "#    except:\n",
    "#        print(f'Fasta file for {protein_id} could not be downloaded.')\n",
    "\n",
    "def download_fasta(protein_id, output_folder):\n",
    "    \"\"\"\n",
    "    Retrieves the fasta file from Uniprot based on protein ID using the REST API\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use the correct UniProt REST API URL\n",
    "        remote_url = f'https://rest.uniprot.org/uniprotkb/{protein_id}.fasta'\n",
    "        local_file = f'{output_folder}/{protein_id}.fasta'\n",
    "        \n",
    "        # Download the file\n",
    "        request.urlretrieve(remote_url, local_file)\n",
    "        \n",
    "        # Verify the file was downloaded and contains data\n",
    "        if os.path.getsize(local_file) == 0:\n",
    "            print(f'Fasta file for {protein_id} is empty. Protein may not exist in UniProt.')\n",
    "            os.remove(local_file)  # Remove empty file\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f'Fasta file for {protein_id} could not be downloaded. Error: {str(e)}')\n",
    "        # Remove any partially downloaded file\n",
    "        if os.path.exists(local_file):\n",
    "            os.remove(local_file)\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "def read_fasta(file_path):\n",
    "    \"\"\"\n",
    "    Reads a .fasta file and returns a Protein Sequence object\n",
    "    \"\"\"\n",
    "    try:\n",
    "\n",
    "        with open(file_path, 'r') as fasta:\n",
    "            content = fasta.readlines()\n",
    "            header = content[0]\n",
    "            sequence = content[1:]\n",
    "            stripped = [line.strip('\\n') for line in sequence]\n",
    "            sequence = ''.join(stripped)\n",
    "            protein_id = header.split('|')[1].strip()\n",
    "        \n",
    "        protein_seq = ProteinSequence(sequence=sequence, protein_id=protein_id, info=header)\n",
    "        return protein_seq\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def load_protein_sequence(protein_id, data_folder) -> ProteinSequence:\n",
    "    \"\"\"\n",
    "    If needed download the .fasta file based on protein ID and return a \n",
    "    ProteinSequence object\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if downloaded\n",
    "    filename = f'{data_folder}/{protein_id}.fasta'\n",
    "    if not os.path.isfile(filename):\n",
    "        download_fasta(protein_id, data_folder)\n",
    "        \n",
    "    protein_seq = read_fasta(filename)\n",
    "    return protein_seq\n",
    "\n",
    "def get_papyrus_proteins(papyrus_file, output_folder, start=0, end=61085165):\n",
    "    \"\"\"\n",
    "    Scans through the whole papyrus dataset, and downloads all required .fasta files from \n",
    "    uniprot, based on protein accesion IDs (attribute[9] in papyrus)\n",
    "\n",
    "    Returns a dict of ProteinSequence objects indexed via protein_ids\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(papyrus_file):\n",
    "        print('Papyrus file not found.')\n",
    "        sys.exit()\n",
    "\n",
    "    end = 61085165 if not end else end\n",
    "    \n",
    "    with open(papyrus_file, 'r') as papyrus:\n",
    "\n",
    "        header = papyrus.readline()\n",
    "        proteins = {}\n",
    "\n",
    "        for idx in tqdm(range(start, end)):\n",
    "            entry = papyrus.readline()\n",
    "            attributes = entry.split('\\t')\n",
    "            protein_id = attributes[9]\n",
    "\n",
    "            if not proteins.get(protein_id):\n",
    "                p_sequence = load_protein_sequence(protein_id, data_folder=output_folder)\n",
    "                proteins[protein_id] = p_sequence\n",
    "            else:\n",
    "                proteins[protein_id].n_ligands += 1\n",
    "    return proteins\n",
    "\n",
    "def get_proteins(pids, output_folder):\n",
    "    \"\"\"\n",
    "    Downloads all required .fasta files from \n",
    "    uniprot, based on protein accesion IDs (attribute[9] in papyrus)\n",
    "\n",
    "    Returns a dict of ProteinSequence objects indexed via protein_ids\n",
    "    \"\"\"\n",
    "    proteins = {}\n",
    "    for protein_id in tqdm(pids):\n",
    "        p_sequence = load_protein_sequence(protein_id, data_folder=output_folder)\n",
    "        proteins[protein_id] = p_sequence\n",
    "    return proteins\n",
    "\n",
    "\n",
    "def get_families(papyrus_targets_file: str, targets: list):\n",
    "\n",
    "    with open(papyrus_targets_file, 'r') as f:\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        header = next(reader)\n",
    "        families = []\n",
    "        target_families = {}\n",
    "        for line in reader:\n",
    "            target = line[0].strip('_WT')\n",
    "            classes = line[5].split('->')\n",
    "            family = classes[1] if len(classes) > 1 else classes[0]\n",
    "            if family == '':\n",
    "                family = 'Unknown'\n",
    "            families += [family]\n",
    "            target_families[target] = family\n",
    "\n",
    "    families = list(set(families))\n",
    "    ## Create a dictionary of families and their members\n",
    "\n",
    "    family_members = {}\n",
    "    for protein in targets:\n",
    "        family = target_families[protein]\n",
    "        if family_members.get(family) is None:\n",
    "            family_members[family] = [protein]\n",
    "        else:\n",
    "            family_members[family] += [protein]\n",
    "\n",
    "    ## Rename some families\n",
    "    modified_families = OrderedDict()\n",
    "    modified_families['Other'] = []\n",
    "    modified_families['G protein-coupled receptor'] = []\n",
    "    cutoff = 25 # Number of families to keep, rest will be grouped into 'Other'\n",
    "\n",
    "    for family in families[:cutoff]:\n",
    "        if 'Other' in family:\n",
    "            modified_families['Other'] += family_members[family]\n",
    "        # Rename all GPCRs\n",
    "        elif 'protein-coupled' in family:\n",
    "            modified_families['G protein-coupled receptor'] += family_members[family]\n",
    "        else:\n",
    "            modified_families[family] = family_members[family]\n",
    "\n",
    "    # All small families are now in 'Other' category\n",
    "    for family in families[cutoff:]:\n",
    "        modified_families['Other'] += family_members[family]\n",
    "\n",
    "    #######\n",
    "    # Create a dictionary of families that is ordered by the number of members\n",
    "    families, family_members = zip(*modified_families.items())\n",
    "    n_members = [len(v) for v in family_members]\n",
    "    # Get sort order\n",
    "    order = np.argsort(n_members)[::-1]\n",
    "    n_members.sort()\n",
    "    fams = list(families)\n",
    "    families = [fams[i] for i in order]\n",
    "    targets = [family_members[i] for i in order]\n",
    "    ordered_families = OrderedDict(zip(families, n_members[::-1]))\n",
    "    families = list(family_members.keys())\n",
    "\n",
    "    return ordered_families\n",
    "\n",
    "def parse_family_data(papyrus_targets_file: str):\n",
    "\n",
    "    with open(papyrus_targets_file, 'r') as f:\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        header = next(reader)\n",
    "        families = []\n",
    "        target_families = {}\n",
    "        for line in reader:\n",
    "            target = line[0].strip('_WT')\n",
    "            classes = line[5].split('->')\n",
    "            family = classes[1] if len(classes) > 1 else classes[0]\n",
    "            if family == '':\n",
    "                family = 'Unknown'\n",
    "            families += [family]\n",
    "            target_families[target] = family\n",
    "\n",
    "    families = list(set(families))\n",
    "    ## Create a dictionary of families and their members\n",
    "\n",
    "    family_members = {}\n",
    "    for protein in targets:\n",
    "        family = target_families[protein]\n",
    "        if family_members.get(family) is None:\n",
    "            family_members[family] = [protein]\n",
    "        else:\n",
    "            family_members[family] += [protein]\n",
    "\n",
    "    ## Rename some families\n",
    "    modified_families = OrderedDict()\n",
    "    modified_families['Other'] = []\n",
    "    modified_families['G protein-coupled receptor'] = []\n",
    "    cutoff = 25 # Number of families to keep, rest will be grouped into 'Other'\n",
    "\n",
    "    for family in families[:cutoff]:\n",
    "        if 'Other' in family:\n",
    "            modified_families['Other'] += family_members[family]\n",
    "        # Rename all GPCRs\n",
    "        elif 'protein-coupled' in family:\n",
    "            modified_families['G protein-coupled receptor'] += family_members[family]\n",
    "        else:\n",
    "            modified_families[family] = family_members[family]\n",
    "\n",
    "    # All small families are now in 'Other' category\n",
    "    for family in families[cutoff:]:\n",
    "        modified_families['Other'] += family_members[family]\n",
    "\n",
    "    #######\n",
    "    # Create a dictionary of families that is ordered by the number of members\n",
    "    families, family_members = zip(*modified_families.items())\n",
    "    n_members = [len(v) for v in family_members]\n",
    "    # Get sort order\n",
    "    order = np.argsort(n_members)[::-1]\n",
    "    n_members.sort()\n",
    "    fams = list(families)\n",
    "    families = [fams[i] for i in order]\n",
    "    targets = [family_members[i] for i in order]\n",
    "    ordered_families = OrderedDict(zip(families, n_members[::-1]))\n",
    "    families = list(family_members.keys())\n",
    "\n",
    "    return ordered_families"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "target_df = pd.read_csv('prot_orgs.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name2_entry         SLCO2B3\n",
       "human_uniprot_id        NaN\n",
       "mouse_uniprot_id        NaN\n",
       "rat_uniprot_id          NaN\n",
       "Name: 50, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_df.iloc[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "targets = target_df['human_uniprot_id'].tolist()\n",
    "print(len(targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protein Seq: P05177, length:                 516, ligands: 0\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('proteins', exist_ok=True)\n",
    "p = load_protein_sequence(targets[0], data_folder='proteins')\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/52 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:11<00:00,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fasta file for nan could not be downloaded. Error: HTTP Error 400: Bad Request\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('serra', exist_ok=True)\n",
    "\n",
    "proteins = get_proteins(targets, output_folder='serra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MALSQSVPFSATELLLASAIFCLVFWVLKGLRPRVPKGLKSPPEPWGWPLLGHVLTLGKNPHLALSRMSQRYGDVLQIRIGSTPVLVLSRLDTIRQALVRQGDDFKGRPDLYTSTLITDGQSLTFSTDSGPVWAARRRLAQNALNTFSIASDPASSSSCYLEEHVSKEAKALISRLQELMAGPGHFDPYNQVVVSVANVIGAMCFGQHFPESSDEMLSLVKNTHEFVETASSGNPLDFFPILRYLPNPALQRFKAFNQRFLWFLQKTVQEHYQDFDKNSVRDITGALFKHSKKGPRASGNLIPQEKIVNLVNDIFGAGFDTVTTAISWSLMYLVTKPEIQRKIQKELDTVIGRERRPRLSDRPQLPYLEAFILETFRHSSFLPFTIPHSTTRDTTLNGFYIPKKCCVFVNQWQVNHDPELWEDPSEFRPERFLTADGTAINKPLSEKMMLFGMGKRRCIGEVLAKWEIFLFLAILLQQLEFSVPPGVKVDLTPIYGLTMKHARCEHVQARLRFSIN', 'MELSVLLFLALLTGLLLLLVQRHPNTHDRLPPGPRPLPLLGNLLQMDRRGLLKSFLRFREKYGDVFTVHLGPRPVVMLCGVEAIREALVDKAEAFSGRGKIAMVDPFFRGYGVIFANGNRWKVLRRFSVTTMRDFGMGKRSVEERIQEEAQCLIEELRKSKGALMDPTFLFQSITANIICSIVFGKRFHYQDQEFLKMLNLFYQTFSLISSVFGQLFELFSGFLKYFPGAHRQVYKNLQEINAYIGHSVEKHRETLDPSAPKDLIDTYLLHMEKEKSNAHSEFSHQNLNLNTLSLFFAGTETTSTTLRYGFLLMLKYPHVAERVYREIEQVIGPHRPPELHDRAKMPYTEAVIYEIQRFSDLLPMGVPHIVTQHTSFRGYIIPKDTEVFLILSTALHDPHYFEKPDAFNPDHFLDANGALKKTEAFIPFSLGKRICLGEGIARAELFLFFTTILQNFSMASPVAPEDIDLTPQECGVGKIPPTYQIRFLPR', 'MDSLVVLVLCLSCLLLLSLWRQSSGRGKLPPGPTPLPVIGNILQIGIKDISKSLTNLSKVYGPVFTLYFGLKPIVVLHGYEAVKEALIDLGEEFSGRGIFPLAERANRGFGIVFSNGKKWKEIRRFSLMTLRNFGMGKRSIEDRVQEEARCLVEELRKTKASPCDPTFILGCAPCNVICSIIFHKRFDYKDQQFLNLMEKLNENIKILSSPWIQICNNFSPIIDYFPGTHNKLLKNVAFMKSYILEKVKEHQESMDMNNPQDFIDCFLMKMEKEKHNQPSEFTIESLENTAVDLFGAGTETTSTTLRYALLLLLKHPEVTAKVQEEIERVIGRNRSPCMQDRSHMPYTDAVVHEVQRYIDLLPTSLPHAVTCDIKFRNYLIPKGTTILISLTSVLHDNKEFPNPEMFDPHHFLDEGGNFKKSKYFMPFSAGKRICVGEALAGMELFLFLTSILQNFNLKSLVDPKNLDTTPVVNGFASVPPFYQLCFIPV', 'MDPFVVLVLCLSCLLLLSIWRQSSGRGKLPPGPTPLPVIGNILQIDIKDVSKSLTNLSKIYGPVFTLYFGLERMVVLHGYEVVKEALIDLGEEFSGRGHFPLAERANRGFGIVFSNGKRWKEIRRFSLMTLRNFGMGKRSIEDRVQEEARCLVEELRKTKASPCDPTFILGCAPCNVICSIIFQKRFDYKDQQFLNLMEKLNENIRIVSTPWIQICNNFPTIIDYFPGTHNKLLKNLAFMESDILEKVKEHQESMDINNPRDFIDCFLIKMEKEKQNQQSEFTIENLVITAADLLGAGTETTSTTLRYALLLLLKHPEVTAKVQEEIERVIGRNRSPCMQDRGHMPYTDAVVHEVQRYIDLIPTSLPHAVTCDVKFRNYLIPKGTTILTSLTSVLHDNKEFPNPEMFDPRHFLDEGGNFKKSNYFMPFSAGKRICVGEGLARMELFLFLTFILQNFNLKSLIDPKDLDTTPVVNGFASVPPFYQLCFIPV', 'MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNLLHVDFQNTPYCFDQLRRRFGDVFSLQLAWTPVVVLNGLAAVREALVTHGEDTADRPPVPITQILGFGPRSQGVFLARYGPAWREQRRFSVSTLRNLGLGKKSLEQWVTEEAACLCAAFANHSGRPFRPNGLLDKAVSNVIASLTCGRRFEYDDPRFLRLLDLAQEGLKEESGFLREVLNAVPVLLHIPALAGKVLRFQKAFLTQLDELLTEHRMTWDPAQPPRDLTEAFLAEMEKAKGNPESSFNDENLRIVVADLFSAGMVTTSTTLAWGLLLMILHPDVQRRVQQEIDDVIGQVRRPEMGDQAHMPYTTAVIHEVQRFGDIVPLGVTHMTSRDIEVQGFRIPKGTTLITNLSSVLKDEAVWEKPFRFHPEHFLDAQGHFVKPEAFLPFSAGRRACLGEPLARMELFLFFTSLLQHFSFSVPTGQPRPSHHGVFAFLVSPSPYELCAVPR', 'MALIPDLAMETWLLLAVSLVLLYLYGTHSHGLFKKLGIPGPTPLPFLGNILSYHKGFCMFDMECHKKYGKVWGFYDGQQPVLAITDPDMIKTVLVKECYSVFTNRRPFGPVGFMKSAISIAEDEEWKRLRSLLSPTFTSGKLKEMVPIIAQYGDVLVRNLRREAETGKPVTLKDVFGAYSMDVITSTSFGVNIDSLNNPQDPFVENTKKLLRFDFLDPFFLSITVFPFLIPILEVLNICVFPREVTNFLRKSVKRMKESRLEDTQKHRVDFLQLMIDSQNSKETESHKALSDLELVAQSIIFIFAGYETTSSVLSFIMYELATHPDVQQKLQEEIDAVLPNKAPPTYDTVLQMEYLDMVVNETLRLFPIAMRLERVCKKDVEINGMFIPKGVVVMIPSYALHRDPKYWTEPEKFLPERFSKKNKDNIDPYIYTPFGSGPRNCIGMRFALMNMKLALIRVLQNFSFKPCKETQIPLKLSLGGLLQPEKPVVLKVESRDGTVSGA', 'MDRASELLFYVNGRKVIEKNVDPETMLLPYLRKKLRLTGTKYGCGGGGCGACTVMISRYNPITKRIRHHPANACLIPICSLYGAAVTTVEGIGSTHTRIHPVQERIAKCHGTQCGFCTPGMVMSIYTLLRNHPEPTLDQLTDALGGNLCRCTGYRPIIDACKTFCKTSGCCQSKENGVCCLDQGINGLPEFEEGSKTSPKLFAEEEFLPLDPTQELIFPPELMIMAEKQSQRTRVFGSERMMWFSPVTLKELLEFKFKYPQAPVIMGNTSVGPEVKFKGVFHPVIISPDRIEELSVVNHAYNGLTLGAGLSLAQVKDILADVVQKLPEEKTQMYHALLKHLGTLAGSQIRNMASLGGHIISRHPDSDLNPILAVGNCTLNLLSKEGKRQIPLNEQFLSKCPNADLKPQEILVSVNIPYSRKWEFVSAFRQAQRQENALAIVNSGMRVFFGEGDGIIRELCISYGGVGPATICAKNSCQKLIGRHWNEQMLDIACRLILNEVSLLGSAPGGKVEFKRTLIISFLFKFYLEVSQILKKMDPVHYPSLADKYESALEDLHSKHHCSTLKYQNIGPKQHPEDPIGHPIMHLSGVKHATGEAIYCDDMPLVDQELFLTFVTSSRAHAKIVSIDLSEALSMPGVVDIMTAEHLSDVNSFCFFTEAEKFLATDKVFCVGQLVCAVLADSEVQAKRAAKRVKIVYQDLEPLILTIEESIQHNSSFKPERKLEYGNVDEAFKVVDQILEGEIHMGGQEHFYMETQSMLVVPKGEDQEMDVYVSTQFPKYIQDIVASTLKLPANKVMCHVRRVGGAFGGKVLKTGIIAAVTAFAANKHGRAVRCVLERGEDMLITGGRHPYLGKYKAGFMNDGRILALDMEHYSNAGASLDESLFVIEMGLLKMDNAYKFPNLRCRGWACRTNLPSNTAFRGFGFPQAALITESCITEVAAKCGLSPEKVRIINMYKEIDQTPYKQEINAKNLIQCWRECMAMSSYSLRKVAVEKFNAENYWKKKGLAMVPLKFPVGLGSRAAGQAAALVHIYLDGSVLVTHGGIEMGQGVHTKMIQVVSRELRMPMSNVHLRGTSTETVPNANISGGSVVADLNGLAVKDACQTLLKRLEPIISKNPKGTWKDWAQTAFDESINLSAVGYFRGYESDMNWEKGEGQPFEYFVYGAACSEVEIDCLTGDHKNIRTDIVMDVGCSINPAIDIGQIEGAFIQGMGLYTIEELNYSPQGILHTRGPDQYKIPAICDMPTELHIALLPPSQNSNTLYSSKGLGESGVFLGCSVFFAIHDAVSAARQERGLHGPLTLNSPLTPEKIRMACEDKFTKMIPRDEPGSYVPWNVPI', 'MTADKLVFFVNGRKVVEKNADPETTLLAYLRRKLGLSGTKLGCGEGGCGACTVMLSKYDRLQNKIVHFSANACLAPICSLHHVAVTTVEGIGSTKTRLHPVQERIAKSHGSQCGFCTPGIVMSMYTLLRNQPEPTMEEIENAFQGNLCRCTGYRPILQGFRTFARDGGCCGGDGNNPNCCMNQKKDHSVSLSPSLFKPEEFTPLDPTQEPIFPPELLRLKDTPRKQLRFEGERVTWIQASTLKELLDLKAQHPDAKLVVGNTEIGIEMKFKNMLFPMIVCPAWIPELNSVEHGPDGISFGAACPLSIVEKTLVDAVAKLPAQKTEVFRGVLEQLRWFAGKQVKSVASVGGNIITASPISDLNPVFMASGAKLTLVSRGTRRTVQMDHTFFPGYRKTLLSPEEILLSIEIPYSREGEYFSAFKQASRREDDIAKVTSGMRVLFKPGTTEVQELALCYGGMANRTISALKTTQRQLSKLWKEELLQDVCAGLAEELHLPPDAPGGMVDFRCTLTLSFFFKFYLTVLQKLGQENLEDKCGKLDPTFASATLLFQKDPPADVQLFQEVPKGQSEEDMVGRPLPHLAADMQASGEAVYCDDIPRYENELSLRLVTSTRAHAKIKSIDTSEAKKVPGFVCFISADDVPGSNITGICNDETVFAKDKVTCVGHIIGAVVADTPEHTQRAAQGVKITYEELPAIITIEDAIKNNSFYGPELKIEKGDLKKGFSEADNVVSGEIYIGGQEHFYLETHCTIAVPKGEAGEMELFVSTQNTMKTQSFVAKMLGVPANRIVVRVKRMGGGFGGKETRSTVVSTAVALAAYKTGRPVRCMLDRDEDMLITGGRHPFLARYKVGFMKTGTVVALEVDHFSNVGNTQDLSQSIMERALFHMDNCYKIPNIRGTGRLCKTNLPSNTAFRGFGGPQGMLIAECWMSEVAVTCGMPAEEVRRKNLYKEGDLTHFNQKLEGFTLPRCWEECLASSQYHARKSEVDKFNKENCWKKRGLCIIPTKFGISFTVPFLNQAGALLHVYTDGSVLLTHGGTEMGQGLHTKMVQVASRALKIPTSKIYISETSTNTVPNTSPTAASVSADLNGQAVYAACQTILKRLEPYKKKNPSGSWEDWVTAAYMDTVSLSATGFYRTPNLGYSFETNSGNPFHYFSYGVACSEVEIDCLTGDHKNLRTDIVMDVGSSLNPAIDIGQVEGAFVQGLGLFTLEELHYSPEGSLHTRGPSTYKIPAFGSIPIEFRVSLLRDCPNKKAIYASKAVGEPPLFLAASIFFAIKDAIRAARAQHTGNNVKELFRLDSPATPEKIRNACVDKFTTLCVTGVPENCKPWSVRV', 'MENQEKASIAGHMFDVVVIGGGISGLSAAKLLTEYGVSVLVLEARDRVGGRTYTIRNEHVDYVDVGGAYVGPTQNRILRLSKELGIETYKVNVSERLVQYVKGKTYPFRGAFPPVWNPIAYLDYNNLWRTIDNMGKEIPTDAPWEAQHADKWDKMTMKELIDKICWTKTARRFAYLFVNINVTSEPHEVSALWFLWYVKQCGGTTRIFSVTNGGQERKFVGGSGQVSERIMDLLGDQVKLNHPVTHVDQSSDNIIIETLNHEHYECKYVINAIPPTLTAKIHFRPELPAERNQLIQRLPMGAVIKCMMYYKEAFWKKKDYCGCMIIEDEDAPISITLDDTKPDGSLPAIMGFILARKADRLAKLHKEIRKKKICELYAKVLGSQEALHPVHYEEKNWCEEQYSGGCYTAYFPPGIMTQYGRVIRQPVGRIFFAGTETATKWSGYMEGAVEAGERAAREVLNGLGKVTEKDIWVQEPESKDVPAVEITHTFWERNLPSVSGLLKIIGFSTSVTALGFVLYKYKLLPRS', 'MSNKCDVVVVGGGISGMAAAKLLHDSGLNVVVLEARDRVGGRTYTLRNQKVKYVDLGGSYVGPTQNRILRLAKELGLETYKVNEVERLIHHVKGKSYPFRGPFPPVWNPITYLDHNNFWRTMDDMGREIPSDAPWKAPLAEEWDNMTMKELLDKLCWTESAKQLATLFVNLCVTAETHEVSALWFLWYVKQCGGTTRIISTTNGGQERKFVGGSGQVSERIMDLLGDRVKLERPVIYIDQTRENVLVETLNHEMYEAKYVISAIPPTLGMKIHFNPPLPMMRNQMITRVPLGSVIKCIVYYKEPFWRKKDYCGTMIIDGEEAPVAYTLDDTKPEGNYAAIMGFILAHKARKLARLTKEERLKKLCELYAKVLGSLEALEPVHYEEKNWCEEQYSGGCYTTYFPPGILTQYGRVLRQPVDRIYFAGTETATHWSGYMEGAVEAGERAAREILHAMGKIPEDEIWQSEPESVDVPAQPITTTFLERHLPSVPGLLRLIGLTTIFSATALGFLAHKRGLLVRV', 'MSSSGTPDLPVLLTDLKIQYTKIFINNEWHDSVSGKKFPVFNPATEEELCQVEEGDKEDVDKAVKAARQAFQIGSPWRTMDASERGRLLYKLADLIERDRLLLATMESMNGGKLYSNAYLNDLAGCIKTLRYCAGWADKIQGRTIPIDGNFFTYTRHEPIGVCGQIIPWNFPLVMLIWKIGPALSCGNTVVVKPAEQTPLTALHVASLIKEAGFPPGVVNIVPGYGPTAGAAISSHMDIDKVAFTGSTEVGKLIKEAAGKSNLKRVTLELGGKSPCIVLADADLDNAVEFAHHGVFYHQGQCCIAASRIFVEESIYDEFVRRSVERAKKYILGNPLTPGVTQGPQIDKEQYDKILDLIESGKKEGAKLECGGGPWGNKGYFVQPTVFSNVTDEMRIAKEEIFGPVQQIMKFKSLDDVIKRANNTFYGLSAGVFTKDIDKAITISSALQAGTVWVNCYGVVSAQCPFGGFKMSGNGRELGEYGFHEYTEVKTVTVKISQKNS', 'MSTAGKVIKCKAAVLWELKKPFSIEEVEVAPPKAHEVRIKMVAVGICGTDDHVVSGTMVTPLPVILGHEAAGIVESVGEGVTTVKPGDKVIPLAIPQCGKCRICKNPESNYCLKNDVSNPQGTLQDGTSRFTCRRKPIHHFLGISTFSQYTVVDENAVAKIDAASPLEKVCLIGCGFSTGYGSAVNVAKVTPGSTCAVFGLGGVGLSAIMGCKAAGAARIIAVDINKDKFAKAKELGATECINPQDYKKPIQEVLKEMTDGGVDFSFEVIGRLDTMMASLLCCHEACGTSVIVGVPPDSQNLSMNPMLLLTGRTWKGAILGGFKSKECVPKLVADFMAKKFSLDALITHVLPFEKINEGFDLLHSGKSIRTILMF', 'MAFMKKYLLPILGLFMAYYYYSANEEFRPEMLQGKKVIVTGASKGIGREMAYHLAKMGAHVVVTARSKETLQKVVSHCLELGAASAHYIAGTMEDMTFAEQFVAQAGKLMGGLDMLILNHITNTSLNLFHDDIHHVRKSMEVNFLSYVVLTVAALPMLKQSNGSIVVVSSLAGKVAYPMVAAYSASKFALDGFFSSIRKEYSVSRVNVSITLCVLGLIDTETAMKAVSGIVHMQAAPKEECALEIIKGGALRQEEVYYDSSLWTTLLIRNPCRKILEFLYSTSYNMDRFINK', 'MSRQLSRARPATVLGAMEMGRRMDAPTSAAVTRAFLERGHTEIDTAFVYSEGQSETILGGLGLRLGGSDCRVKIDTKAIPLFGNSLKPDSLRFQLETSLKRLQCPRVDLFYLHMPDHSTPVEETLRACHQLHQEGKFVELGLSNYAAWEVAEICTLCKSNGWILPTVYQGMYNAITRQVETELFPCLRHFGLRFYAFNPLAGGLLTGKYKYEDKNGKQPVGRFFGNTWAEMYRNRYWKEHHFEGIALVEKALQAAYGASAPSMTSATLRWMYHHSQLQGAHGDAVILGMSSLEQLEQNLAAAEEGPLEPAVVDAFNQAWHLVTHECPNYFR', 'MAKRVAIVGAGVSGLASIKCCLEEGLEPTCFERSDDLGGLWRFTEHVEEGRASLYKSVVSNSCKEMSCYSDFPFPEDYPNYVPNSQFLEYLKMYANHFDLLKHIQFKTKVCSVTKCSDSAVSGQWEVVTMHEEKQESAIFDAVMVCTGFLTNPYLPLDSFPGINAFKGQYFHSRQYKHPDIFKDKRVLVIGMGNSGTDIAVEASHLAEKVFLSTTGGGWVISRIFDSGYPWDMVFMTRFQNMLRNSLPTPIVTWLMERKINNWLNHANYGLIPEDRTQLKEFVLNDELPGRIITGKVFIRPSIKEVKENSVIFNNTSKEEPIDIIVFATGYTFAFPFLDESVVKVEDGQASLYKYIFPAHLQKPTLAIIGLIKPLGSMIPTGETQARWAVRVLKGVNKLPPPSVMIEEINARKENKPSWFGLCYCKALQSDYITYIDELLTYINAKPNLFSMLLTDPHLALTVFFGPCSPYQFRLTGPGKWEGARNAIMTQWDRTFKVIKARVVQESPSPFESFLKVFSFLALLVAIFLIFL', 'MNSSSANITYASRKRRKPVQKTVKPIPAEGIKSNPSKRHRDRLNTELDRLASLLPFPQDVINKLDKLSVLRLSVSYLRAKSFFDVALKSSPTERNGGQDNCRAANFREGLNLQEGEFLLQALNGFVLVVTTDALVFYASSTIQDYLGFQQSDVIHQSVYELIHTEDRAEFQRQLHWALNPSQCTESGQGIEEATGLPQTVVCYNPDQIPPENSPLMERCFICRLRCLLDNSSGFLAMNFQGKLKYLHGQKKKGKDGSILPPQLALFAIATPLQPPSILEIRTKNFIFRTKHKLDFTPIGCDAKGRIVLGYTEAELCTRGSGYQFIHAADMLYCAESHIRMIKTGESGMIVFRLLTKNNRWTWVQSNARLLYKNGRPDYIIVTQRPLTDEEGTEHLRKRNTKLPFMFTTGEAVLYEATNPFPAIMDPLPLRTKNGTSGKDSATTSTLSKDSLNPSSLLAAMMQQDESIYLYPASSTSSTAPFENNFFNESMNECRNWQDNTAPMGNDTILKHEQIDQPQDVNSFAGGHPGLFQDSKNSDLYSIMKNLGIDFEDIRHMQNEKFFRNDFSGEVDFRDIDLTDEILTYVQDSLSKSPFIPSDYQQQQSLALNSSCMVQEHLHLEQQQQHHQKQVVVEPQQQLCQKMKHMQVNGMFENWNSNQFVPFNCPQQDPQQYNVFTDLHGISQEFPYKSEMDSMPYTQNFISCNQPVLPQHSKCTELDYPMGSFEPSPYPTTSSLEDFVTCLQLPENQKHGLNPQSAIITPQTCYAGAVSMYQCQPEPQHTHVGQMQYNPVLPGQQAFLNKFQNGVLNETYPAELNNINNTQTTTHLQPLHHPSEARPFPDLTSSGFL', 'MASREDELRNCVVCGDQATGYHFNALTCEGCKGFFRRTVSKSIGPTCPFAGSCEVSKTQRRHCPACRLQKCLDAGMRKDMILSAEALALRRAKQAQRRAQQTPVQLSKEQEELIRTLLGAHTRHMGTMFEQFVQFRPPAHLFIHHQPLPTLAPVLPLVTHFADINTFMVLQVIKFTKDLPVFRSLPIEDQISLLKGAAVEICHIVLNTTFCLQTQNFLCGPLRYTIEDGARVSPTVGFQVEFLELLFHFHGTLRKLQLQEPEYVLLAAMALFSPDRPGVTQRDEIDQLQEEMALTLQSYIKGQQRRPRDRFLYAKLLGLLAELRSINEAYGYQIQHIQGLSAMMPLLQEICS', 'MEVRPKESWNHADFVHCEDTESVPGKPSVNADEEVGGPQICRVCGDKATGYHFNVMTCEGCKGFFRRAMKRNARLRCPFRKGACEITRKTRRQCQACRLRKCLESGMKKEMIMSDEAVEERRALIKRKKSERTGTQPLGVQGLTEEQRMMIRELMDAQMKTFDTTFSHFKNFRLPGVLSSGCELPESLQAPSREEAAKWSQVRKDLCSLKVSLQLRGEDGSVWNYKPPADSGGKEIFSLLPHMADMSTYMFKGIISFAKVISYFRDLPIEDQISLLKGAAFELCQLRFNTVFNAETGTWECGRLSYCLEDTAGGFQQLLLEPMLKFHYMLKKLQLHEEEYVLMQAISLFSPDRPGVLQHRVVDQLQEQFAITLKSYIECNRPQPAHRFLFLKIMAMLTELRSINAQHTQRLLRIQDIHPFATPLMQELFGITGS', 'MELIQDTSRPPLEYVKGVPLIKYFAEALGPLQSFQARPDDLLISTYPKSGTTWVSQILDMIYQGGDLEKCHRAPIFMRVPFLEFKAPGIPSGMETLKDTPAPRLLKTHLPLALLPQTLLDQKVKVVYVARNAKDVAVSYYHFYHMAKVHPEPGTWDSFLEKFMVGEVSYGSWYQHVQEWWELSRTHPVLYLFYEDMKENPKREIQKILEFVGRSLPEETVDFVVQHTSFKEMKKNPMTNYTTVPQEFMDHSISPFMRKGMAGDWKTTFTVAQNERFDADYAEKMAGCSLSFRSEL', 'MAEKPKLHYFNARGRMESTRWLLAAAGVEFEEKFIKSAEDLDKLRNDGYLMFQQVPMVEIDGMKLVQTRAILNYIASKYNLYGKDIKERALIDMYIEGIADLGEMILLLPVCPPEEKDAKLALIKEKIKNRYFPAFEKVLKSHGQDYLVGNKLSRADIHLVELLYYVEELDSSLISSFPLLKALKTRISNLPTVKKFLQPGSPRKPPMDEKSLEEARKIFRF', 'MAMGLMCGRRELLRLLQSGRRVHSVAGPSQWLGKPLTTRLLFPAAPCCCRPHYLFLAASGPRSLSTSAISFAEVQVQAPPVVAATPSPTAVPEVASGETADVVQTAAEQSFAELGLGSYTPVGLIQNLLEFMHVDLGLPWWGAIAACTVFARCLIFPLIVTGQREAARIHNHLPEIQKFSSRIREAKLAGDHIEYYKASSEMALYQKKHGIKLYKPLILPVTQAPIFISFFIALREMANLPVPSLQTGGLWWFQDLTVSDPIYILPLAVTATMWAVLELGAETGVQSSDLQWMRNVIRMMPLITLPITMHFPTAVFMYWLSSNLFSLVQVSCLRIPAVRTVLKIPQRVVHDLDKLPPREGFLESFKKGWKNAEMTRQLREREQRMRNQLELAARGPLRQTFTHNPLLQPGKDNPPNIPSSSSKPKSKYPWHDTLG', 'MALSWVLTVLSLLPLLEAQIPLCANLVPVPITNATLDRITGKWFYIASAFRNEEYNKSVQEIQATFFYFTPNKTEDTIFLREYQTRQDQCIYNTTYLNVQRENGTISRYVGGQEHFAHLLILRDTKTYMLAFDVNDEKNWGLSVYADKPETTKEQLGEFYEALDCLRIPKSDVVYTDWKKDKCEPLEKQHEKERKQEEGES', 'MPVRRGHVAPQNTFLDTIIRKFEGQSRKFIIANARVENCAVIYCNDGFCELCGYSRAEVMQRPCTCDFLHGPRTQRRAAAQIAQALLGAEERKVEIAFYRKDGSCFLCLVDVVPVKNEDGAVIMFILNFEVVMEKDMVGSPAHDTNHRGPPTSWLAPGRAKTFRLKLPALLALTARESSVRSGGAGGAGAPGAVVVDVDLTPAAPSSESLALDEVTAMDNHVAGLGPAEERRALVGPGSPPRSAPGQLPSPRAHSLNPDASGSSCSLARTRSRESCASVRRASSADDIEAMRAGVLPPPPRHASTGAMHPLRSGLLNSTSDSDLVRYRTISKIPQITLNFVDLKGDPFLASPTSDREIIAPKIKERTHNVTEKVTQVLSLGADVLPEYKLQAPRIHRWTILHYSPFKAVWDWLILLLVIYTAVFTPYSAAFLLKETEEGPPATECGYACQPLAVVDLIVDIMFIVDILINFRTTYVNANEEVVSHPGRIAVHYFKGWFLIDMVAAIPFDLLIFGSGSEELIGLLKTARLLRLVRVARKLDRYSEYGAAVLFLLMCTFALIAHWLACIWYAIGNMEQPHMDSRIGWLHNLGDQIGKPYNSSGLGGPSIKDKYVTALYFTFSSLTSVGFGNVSPNTNSEKIFSICVMLIGSLMYASIFGNVSAIIQRLYSGTARYHTQMLRVREFIRFHQIPNPLRQRLEEYFQHAWSYTNGIDMNAVLKGFPECLQADICLHLNRSLLQHCKPFRGATKGCLRALAMKFKTTHAPPGDTLVHAGDLLTALYFISRGSIEILRGDVVVAILGKNDIFGEPLNLYARPGKSNGDVRALTYCDLHKIHRDDLLEVLDMYPEFSDHFWSSLEITFNLRDTNMIPGSPGSTELEGGFSRQRKRKLSFRRRTDKDTEQPGEVSALGPGRAGAGPSSRGRPGGPWGESPSSGPSSPESSEDEGPGRSSSPLRLVPFSSPRPPGEPPGGEPLMEDCEKSSDTCNPLSGAFSGVSNIFSFWGDSRGRQYQELPRCPAPTPSLLNIPLSSPGRRPRGDVESRLDALQRQLNRLETRLSADMATVLQLLQRQMTLVPPAYSAVTTPGPGPTSTSPLLPVSPLPTLTLDSLSQVSQFMACEELPPGAPELPQEGPTRRLSLPGQLGALTSQPLHRHGSDPGS', 'MANFLLPRGTSSFRRFTRESLAAIEKRMAEKQARGSTTLQESREGLPEEEAPRPQLDLQASKKLPDLYGNPPQELIGEPLEDLDPFYSTQKTFIVLNKGKTIFRFSATNALYVLSPFHPIRRAAVKILVHSLFNMLIMCTILTNCVFMAQHDPPPWTKYVEYTFTAIYTFESLVKILARGFCLHAFTFLRDPWNWLDFSVIIMAYTTEFVDLGNVSALRTFRVLRALKTISVISGLKTIVGALIQSVKKLADVMVLTVFCLSVFALIGLQLFMGNLRHKCVRNFTALNGTNGSVEADGLVWESLDLYLSDPENYLLKNGTSDVLLCGNSSDAGTCPEGYRCLKAGENPDHGYTSFDSFAWAFLALFRLMTQDCWERLYQQTLRSAGKIYMIFFMLVIFLGSFYLVNLILAVVAMAYEEQNQATIAETEEKEKRFQEAMEMLKKEHEALTIRGVDTVSRSSLEMSPLAPVNSHERRSKRRKRMSSGTEECGEDRLPKSDSEDGPRAMNHLSLTRGLSRTSMKPRSSRGSIFTFRRRDLGSEADFADDENSTAGESESHHTSLLVPWPLRRTSAQGQPSPGTSAPGHALHGKKNSTVDCNGVVSLLGAGDPEATSPGSHLLRPVMLEHPPDTTTPSEEPGGPQMLTSQAPCVDGFEEPGARQRALSAVSVLTSALEELEESRHKCPPCWNRLAQRYLIWECCPLWMSIKQGVKLVVMDPFTDLTITMCIVLNTLFMALEHYNMTSEFEEMLQVGNLVFTGIFTAEMTFKIIALDPYYYFQQGWNIFDSIIVILSLMELGLSRMSNLSVLRSFRLLRVFKLAKSWPTLNTLIKIIGNSVGALGNLTLVLAIIVFIFAVVGMQLFGKNYSELRDSDSGLLPRWHMMDFFHAFLIIFRILCGEWIETMWDCMEVSGQSLCLLVFLLVMVIGNLVVLNLFLALLLSSFSADNLTAPDEDREMNNLQLALARIQRGLRFVKRTTWDFCCGLLRQRPQKPAALAAQGQLPSCIATPYSPPPPETEKVPPTRKETRFEEGEQPGQGTPGDPEPVCVPIAVAESDTDDQEEDEENSLGTEEESSKQQESQPVSGGPEAPPDSRTWSQVSATASSEAEASASQADWRQQWKAEPQAPGCGETPEDSCSEGSTADMTNTAELLEQIPDLGQDVKDPEDCFTEGCVRRCPCCAVDTTQAPGKVWWRLRKTCYHIVEHSWFETFIIFMILLSSGALAFEDIYLEERKTIKVLLEYADKMFTYVFVLEMLLKWVAYGFKKYFTNAWCWLDFLIVDVSLVSLVANTLGFAEMGPIKSLRTLRALRPLRALSRFEGMRVVVNALVGAIPSIMNVLLVCLIFWLIFSIMGVNLFAGKFGRCINQTEGDLPLNYTIVNNKSQCESLNLTGELYWTKVKVNFDNVGAGYLALLQVATFKGWMDIMYAAVDSRGYEEQPQWEYNLYMYIYFVIFIIFGSFFTLNLFIGVIIDNFNQQKKKLGGQDIFMTEEQKKYYNAMKKLGSKKPQKPIPRPLNKYQGFIFDIVTKQAFDVTIMFLICLNMVTMMVETDDQSPEKINILAKINLLFVAIFTGECIVKLAALRHYYFTNSWNIFDFVVVILSIVGTVLSDIIQKYFFSPTLFRVIRLARIGRILRLIRGAKGIRTLLFALMMSLPALFNIGLLLFLVMFIYSIFGMANFAYVKWEAGIDDMFNFQTFANSMLCLFQITTSAGWDGLLSPILNTGPPYCDPTLPNSNGSRGDCGSPAVGILFFTTYIIISFLIVVNMYIAIILENFSVATEESTEPLSEDDFDMFYEIWEKFDPEATQFIEYSVLSDFADALSEPLRIAKPNQISLINMDLPMVSGDRIHCMDILFAFTKRVLGESGEMDALKIQMEEKFMAANPSKISYEPITTTLRRKHEEVSAMVIQRAFRRHLLQRSLKHASFLFRQQAGSGLSEEDAPEREGLIAYVMSENFSRPLGPPSSSSISSTSFPPSYDSVTRATSDNLQVRGSDYSHSEDLADFPPSPDRDRESIV', 'MVQKTSMSRGPYPPSQEIPMEVFDPSPQGKYSKRKGRFKRSDGSTSSDTTSNSFVRQGSAESYTSRPSDSDVSLEEDREALRKEAERQALAQLEKAKTKPVAFAVRTNVGYNPSPGDEVPVQGVAITFEPKDFLHIKEKYNNDWWIGRLVKEGCEVGFIPSPVKLDSLRLLQEQKLRQNRLGSSKSGDNSSSSLGDVVTGTRRPTPPASAKQKQKSTEHVPPYDVVPSMRPIILVGPSLKGYEVTDMMQKALFDFLKHRFDGRISITRVTADISLAKRSVLNNPSKHIIIERSNTRSSLAEVQSEIERIFELARTLQLVALDADTINHPAQLSKTSLAPIIVYIKITSPKVLQRLIKSRGKSQSKHLNVQIAASEKLAQCPPEMFDIILDENQLEDACEHLAEYLEAYWKATHPPSSTPPNPLLNRTMATAALAASPAPVSNLQGPYLASGDQPLERATGEHASMHEYPGELGQPPGLYPSSHPPGRAGTLRALSRQDTFDADTPGSRNSAYTELGDSCVDMETDPSEGPGLGDPAGGGTPPARQGSWEDEEEDYEEELTDNRNRGRNKARYCAEGGGPVLGRNKNELEGWGRGVYIR', 'MSGGKYVDSEGHLYTVPIREQGNIYKPNNKAMADELSEKQVYDAHTKEIDLVNRDPKHLNDDVVKIDFEDVIAEPEGTHSFDGIWKASFTTFTVTKYWFYRLLSALFGIPMALIWGIYFAILSFLHIWAVVPCIKSFLIEIQCISRVYSIYVHTVCDPLFEAVGKIFSNVRINLQKEI', 'MALSYRVSELQSTIPEHILQSTFVHVISSNWSGLQTESIPEEMKQIVEEQGNKLHWAALLILMVIIPTIGGNTLVILAVSLEKKLQYATNYFLMSLAVADLLVGLFVMPIALLTIMFEAMWPLPLVLCPAWLFLDVLFSTASIMHLCAISVDRYIAIKKPIQANQYNSRATAFIKITVVWLISIGIAIPVPIKGIETDVDNPNNITCVLTKERFGDFMLFGSLAAFFTPLAIMIVTYFLTIHALQKKAYLVKNKPPQRLTWLTVSTVFQRDETPCSSPEKVAMLDGSRKDKALPNSGDETLMRRTSTIGKKSVQTISNEQRASKVLGIVFFLFLLMWCPFFITNITLVLCDSCNQTTLQMLLEIFVWIGYVSSGVNPLVYTLFNKTFRDAFGRYITCNYRATKSVKTLRKRSSKIYFRNPMAENSKFFKKHGIRNGINPAMYQSPMRLRSSTIQSSSIILLDTLLLTENEGDKTEEQVSYV', 'METTPLNSQKQLSACEDGEDCQENGVLQKVVPTPGDKVESGQISNGYSAVPSPGAGDDTRHSIPATTTTLVAELHQGERETWGKKVDFLLSVIGYAVDLGNVWRFPYICYQNGGGAFLLPYTIMAIFGGIPLFYMELALGQYHRNGCISIWRKICPIFKGIGYAICIIAFYIASYYNTIMAWALYYLISSFTDQLPWTSCKNSWNTGNCTNYFSEDNITWTLHSTSPAEEFYTRHVLQIHRSKGLQDLGGISWQLALCIMLIFTVIYFSIWKGVKTSGKVVWVTATFPYIILSVLLVRGATLPGAWRGVLFYLKPNWQKLLETGVWIDAAAQIFFSLGPGFGVLLAFASYNKFNNNCYQDALVTSVVNCMTSFVSGFVIFTVLGYMAEMRNEDVSEVAKDAGPSLLFITYAEAIANMPASTFFAIIFFLMLITLGLDSTFAGLEGVITAVLDEFPHVWAKRRERFVLAVVITCFFGSLVTLTFGGAYVVKLLEEYATGPAVLTVALIEAVAVSWFYGITQFCRDVKEMLGFSPGWFWRICWVAISPLFLLFIICSFLMSPPQLRLFQYNYPYWSIILGYCIGTSSFICIPTYIAYRLIITPGTFKERIIKSITPETPTEIPCGDIRLNAV', 'MDDKGDPSNEEAPKAIKPTSKEFRKTWGFRRTTIAKREGAGDAEADPLEPPPPQQQLGLSLRRSGRQPKRTERVEQFLTIARRRGRRSMPVSLEDSGEPTSCPATDAETASEGSVESASETRSGPQSASTAVKERPASSEKVKGGDDHDDTSDSDSDGLTLKELQNRLRRKREQEPTERPLKGIQSRLRKKRREEGPAETVGSEASDTVEGVLPSKQEPENDQGVVSQAGKDDRESKLEGKAAQDIKDEEPGDLGRPKPECEGYDPNALYCICRQPHNNRFMICCDRCEEWFHGDCVGISEARGRLLERNGEDYICPNCTILQVQDETHSETADQQEAKWRPGDADGTDCTSIGTIEQKSSEDQGIKGRIEKAANPSGKKKLKIFQPVIEAPGASKCIGPGCCHVAQPDSVYCSNDCILKHAAATMKFLSSGKEQKPKPKEKMKMKPEKPSLPKCGAQAGIKISSVHKRPAPEKKETTVKKAVVVPARSEALGKEAACESSTPSWASDHNYNAVKPEKTAAPSPSLLYKSTKEDRRSEEKAAAMAASKKTAPPGSAVGKQPAPRNLVPKKSSFANVAAATPAIKKPPSGFKGTIPKRPWLSATPSSGASAARQAGPAPAAATAASKKFPGSAALVGAVRKPVVPSVPMASPAPGRLGAMSAAPSQPNSQIRQNIRRSLKEILWKRVNDSDDLIMTENEVGKIALHIEKEMFNLFQVTDNRYKSKYRSIMFNLKDPKNQGLFHRVLREEISLAKLVRLKPEELVSKELSTWKERPARSVMESRTKLHNESKKTAPRQEAIPDLEDSPPVSDSEEQQESARAVPEKSTAPLLDVFSSMLKDTTSQHRAHLFDLNCKICTGQVPSAEDEPAPKKQKLSASVKKEDLKSKHDSSAPDPAPDSADEVMPEAVPEVASEPGLESASHPNVDRTYFPGPPGDGHPEPSPLEDLSPCPASCGSGVVTTVTVSGRDPRTAPSSSCTAVASAASRPDSTHMVEARQDVPKPVLTSVMVPKSILAKPSSSPDPRYLSVPPSPNISTSESRSPPEGDTTLFLSRLSTIWKGFINMQSVAKFVTKAYPVSGCFDYLSEDLPDTIHIGGRIAPKTVWDYVGKLKSSVSKELCLIRFHPATEEEEVAYISLYSYFSSRGRFGVVANNNRHVKDLYLIPLSAQDPVPSKLLPFEGPGLESPRPNIILGLVICQKIKRPANSGELDKMDEKRTRLQPEEADVPAYPKVATVPQSEKKPSKYPLCSADAAVSTTPPGSPPPPPPLPEPPVLKVLSSLKPAAPSPATAATTAAAASTAASSTASSASKTASPLEHILQTLFGKKKSFDPSAREPPGSTAGLPQEPKTTAEDGVPAPPLLDPIVQQFGQFSKDKALEEEEDDRPYDPEEEYDPERAFDTQLVERGRRHEVERAPEAAAAEREEVAYDPEDETILEEAKVTVDDLPNRMCADVRRNSVERPAEPVAGAATPSLVEQQKMLEELNKQIEEQKRQLEEQEEALRQQRAAVGVSMAHFSVSDALMSPPPKSSLPKAELFQQEQQSADKPASLPPASQASNHRDPRQARRLATETGEGEGEPLSRLSARGAQGALPERDASRGGLVGQAPMPVPEEKEPASSPWASGEKPPAGSEQDGWKAEPGEGTRPATVGDSSARPARRVLLPTPPCGALQPGFPLQHDGERDPFTCPGFASQDKALGSAQYEDPRNLHSAGRSSSPAGETEGDREPQARPGEGTAPLPPPGQKVGGSQPPFQGQREPGPHALGMSGLHGPNFPGPRGPAPPFPEENIASNDGPRGPPPARFGAQKGPIPSLFSGQHGPPPYGDSRGPSPSYLGGPRGVAPSQFEERKDPHGEKREFQDAPYNEVTGAPAQFEGTEQAPFLGSRGGAPFQFGGQRRPLLSQLKGPRGGPPPSQFGGQRGPPPGHFVGPRGPHPSQFETARGPHPNQFEGPRGQAPNFMPGPRGIQPQQFEDQRVHSPPRFTNQRAPAPLQFGGLRGSAPFSEKNEQTPSRFHFQGQAPQVMKPGPRPLLELPSHPPQHRKDRWEEAGPPSALSSSAPGQGPEADGQWASADFREGKGHEYRNQTFEGRQRERFDVGPKEKPLEEPDAQGRASEDRRRERERGRNWSRERDWDRPREWDRHRDKDSSRDWDRNRERSANRDREREADRGKEWDRSRERSRNRERERDRRRDRDRSRSRERDRDKARDRERGRDRKDRSKSKESARDPKPEASRASDAGTASQA', 'MSKSKCSVGLMSSVVAPAKEPNAVGPKEVELILVKEQNGVQLTSSTLTNPRQSPVEAQDRETWGKKIDFLLSVIGFAVDLANVWRFPYLCYKNGGGAFLVPYLLFMVIAGMPLFYMELALGQFNREGAAGVWKICPILKGVGFTVILISLYVGFFYNVIIAWALHYLFSSFTTELPWIHCNNSWNSPNCSDAHPGDSSGDSSGLNDTFGTTPAAEYFERGVLHLHQSHGIDDLGPPRWQLTACLVLVIVLLYFSLWKGVKTSGKVVWITATMPYVVLTALLLRGVTLPGAIDGIRAYLSVDFYRLCEASVWIDAATQVCFSLGVGFGVLIAFSSYNKFTNNCYRDAIVTTSINSLTSFSSGFVVFSFLGYMAQKHSVPIGDVAKDGPGLIFIIYPEAIATLPLSSAWAVVFFIMLLTLGIDSAMGGMESVITGLIDEFQLLHRHRELFTLFIVLATFLLSLFCVTNGGIYVFTLLDHFAAGTSILFGVLIEAIGVAWFYGVGQFSDDIQQMTGQRPSLYWRLCWKLVSPCFLLFVVVVSIVTFRPPHYGAYIFPDWANALGWVIATSSMAMVPIYAAYKFCSLPGSFREKLAYAIAPEKDRELVDRGEVRQFTLRHWLKV', 'MLLARMNPQVQPENNGADTGPEQPLRARKTAELLVVKERNGVQCLLAPRDGDAQPRETWGKKIDFLLSVVGFAVDLANVWRFPYLCYKNGGGAFLIPYTLFLIIAGMPLFYMELALGQYNREGAATVWKICPFFKGVGYAVILIALYVGFYYNVIIAWSLYYLFSSFTLNLPWTDCGHTWNSPNCTDPKLLNGSVLGNHTKYSKYKFTPAAEFYERGVLHLHESSGIHDIGLPQWQLLLCLMVVVIVLYFSLWKGVKTSGKVVWITATLPYFVLFVLLVHGVTLPGASNGINAYLHIDFYRLKEATVWIDAATQIFFSLGAGFGVLIAFASYNKFDNNCYRDALLTSSINCITSFVSGFAIFSILGYMAHEHKVNIEDVATEGAGLVFILYPEAISTLSGSTFWAVVFFVMLLALGLDSSMGGMEAVITGLADDFQVLKRHRKLFTFGVTFSTFLLALFCITKGGIYVLTLLDTFAAGTSILFAVLMEAIGVSWFYGVDRFSNDIQQMMGFRPGLYWRLCWKFVSPAFLLFVVVVSIINFKPLTYDDYIFPPWANWVGWGIALSSMVLVPIYVIYKFLSTQGSLWERLAYGITPENEHHLVAQRDIRQFQLQHWLAI', 'MAPCHIRKYQESDRQWVVGLLSRGMAEHAPATFRQLLKLPRTLILLLGGPLALLLVSGSWLLALVFSISLFPALWFLAKKPWTEYVDMTLCTDMSDITKSYLSERGSCFWVAESEEKVVGMVGALPVDDPTLREKRLQLFHLFVDSEHRRQGIAKALVRTVLQFARDQGYSEVILDTGTIQLSAMALYQSMGFKKTGQSFFCVWARLVALHTVHFIYHLPSSKVGSL', 'MTFRDLLSVSFEGPRPDSSAGGSSAGGGGGSAGGAAPSEGPAVGGVPGGAGGGGGVVGAGSGEDNRSSAGEPGSAGAGGDVNGTAAVGGLVVSAQGVGVGVFLAAFILMAVAGNLLVILSVACNRHLQTVTNYFIVNLAVADLLLSATVLPFSATMEVLGFWAFGRAFCDVWAAVDVLCCTASILSLCTISVDRYVGVRHSLKYPAIMTERKAAAILALLWVVALVVSVGPLLGWKEPVPPDERFCGITEEAGYAVFSSVCSFYLPMAVIVVMYCRVYVVARSTTRSLEAGVKRERGKASEVVLRIHCRGAATGADGAHGMRSAKGHTFRSSLSVRLLKFSREKKAAKTLAIVVGVFVLCWFPFFFVLPLGSLFPQLKPSEGVFKVIFWLGYFNSCVNPLIYPCSSREFKRAFLRLLRCQCRRRRRRRPLWRVYGHHWRASTSGLRQDCAPSSGDAPPGAPLALTALPDPDPEPPGTPEMQAPVASRRKPPSAFREWRLLGPFRRPTTQLRAKVSSLSHKIRAGGAQRAEAACAQRSEVEAVSLGVPHEVAEGATCQAYELADYSNLRETDI', 'MFRQEQPLAEGSFAPMGSLQPDAGNASWNGTEAPGGGARATPYSLQVTLTLVCLAGLLMLLTVFGNVLVIIAVFTSRALKAPQNLFLVSLASADILVATLVIPFSLANEVMGYWYFGKAWCEIYLALDVLFCTSSIVHLCAISLDRYWSITQAIEYNLKRTPRRIKAIIITVWVISAVISFPPLISIEKKGGGGGPQPAEPRCEINDQKWYVISSCIGSFFAPCLIMILVYVRIYQIAKRRTRVPPSRRGPDAVAAPPGGTERRPNGLGPERSAGPGGAEAEPLPTQLNGAPGEPAPAGPRDTDALDLEESSSSDHAERPPGPRRPERGPRGKGKARASQVKPGDSLPRRGPGATGIGTPAAGPGEERVGAAKASRWRGRQNREKRFTFVLAVVIGVFVVCWFPFFFTYTLTAVGCSVPRTLFKFFFWFGYCNSSLNPVIYTIFNHDFRRAFKKILCRGDRKRIV', 'MGAGVLVLGASEPGNLSSAAPLPDGAATAARLLVPASPPASLLPPASESPEPLSQQWTAGMGLLMALIVLLIVAGNVLVIVAIAKTPRLQTLTNLFIMSLASADLVMGLLVVPFGATIVVWGRWEYGSFFCELWTSVDVLCVTASIETLCVIALDRYLAITSPFRYQSLLTRARARGLVCTVWAISALVSFLPILMHWWRAESDEARRCYNDPKCCDFVTNRAYAIASSVVSFYVPLCIMAFVYLRVFREAQKQVKKIDSCERRFLGGPARPPSPSPSPVPAPAPPPGPPRPAAAAATAPLANGRAGKRRPSRLVALREQKALKTLGIIMGVFTLCWLPFFLANVVKAFHRELVPDRLFVFFNWLGYANSAFNPIIYCRSPDFRKAFQGLLCCARRAARRRHATHGDRPRASGCLARPGPPPSPGAASDDDDDDVVGATPPARLLEPWAGCNGGAAADSDSSLDEPCRPGFASESKV', 'MGQPGNGSAFLLAPNGSHAPDHDVTQERDEVWVVGMGIVMSLIVLAIVFGNVLVITAIAKFERLQTVTNYFITSLACADLVMGLAVVPFGAAHILMKMWTFGNFWCEFWTSIDVLCVTASIETLCVIAVDRYFAITSPFKYQSLLTKNKARVIILMVWIVSGLTSFLPIQMHWYRATHQEAINCYANETCCDFFTNQAYAIASSIVSFYVPLVIMVFVYSRVFQEAKRQLQKIDKSEGRFHVQNLSQVEQDGRTGHGLRRSSKFCLKEHKALKTLGIIMGTFTLCWLPFFIVNIVHVIQDNLIRKEVYILLNWIGYVNSGFNPLIYCRSPDFRIAFQELLCLRRSSLKAYGNGYSSNGNTGEQSGYHVEQEKENKLLCEDLPGTEDFVGHQGTVPSDNIDSQGRNCSTNDSLL', 'MGDLPGLVRLSIALRIQPNDGPVFYKVDGQRFGQNRTIKLLTGSSYKVEVKIKPSTLQVENISIGGVLVPLELKSKEPDGDRVVYTGTYDTEGVTPTKSGERQPIQITMPFTDIGTFETVWQVKFYNYHKRDHCQWGSPFSVIEYECKPNETRSLMWVNKESFL', 'MEECWVTEIANGSKDGLDSNPMKDYMILSGPQKTAVAVLCTLLGLLSALENVAVLYLILSSHQLRRKPSYLFIGSLAGADFLASVVFACSFVNFHVFHGVDSKAVFLLKIGSVTMTFTASVGSLLLTAIDRYLCLRYPPSYKALLTRGRALVTLGIMWVLSALVSYLPLMGWTCCPRPCSELFPLIPNDYLLSWLLFIAFLFSGIIYTYGHVLWKAHQHVASLSGHQDRQVPGMARMRLDVRLAKTLGLVLAVLLICWFPVLALMAHSLATTLSDQVKKAFAFCSMLCLINSMVNPVIYALRSGEIRSSAHHCLAHWKKCVRGLGSEAKEEAPRSSVTETEADGKITPWPDSRDLDLSDC', 'MNTSAPPAVSPNITVLAPGKGPWQVAFIGITTGLLSLATVTGNLLVLISFKVNTELKTVNNYFLLSLACADLIIGTFSMNLYTTYLLMGHWALGTLACDLWLALDYVASNASVMNLLLISFDRYFSVTRPLSYRAKRTPRRAALMIGLAWLVSFVLWAPAILFWQYLVGERTVLAGQCYIQFLSQPIITFGTAMAAFYLPVTVMCTLYWRIYRETENRARELAALQGSETPGKGGGSSSSSERSQPGAEGSPETPPGRCCRCCRAPRLLQAYSWKEEEEEDEGSMESLTSSEGEEPGSEVVIKMPMVDPEAQAPTKQPPRSSPNTVKRPTKKGRDRAGKGQKPRGKEQLAKRKTFSLVKEKKAARTLSAILLAFILTWTPYNIMVLVSTFCKDCVPETLWELGYWLCYVNSTINPMCYALCNKAFRDTFRLLLLCRWDKRRWRKIPKRPGSVHRTPSRQC', 'MNNSTNSSNNSLALTSPYKTFEVVFIVLVAGSLSLVTIIGNILVMVSIKVNRHLQTVNNYFLFSLACADLIIGVFSMNLYTLYTVIGYWPLGPVVCDLWLALDYVVSNASVMNLLIISFDRYFCVTKPLTYPVKRTTKMAGMMIAAAWVLSFILWAPAILFWQFIVGVRTVEDGECYIQFFSNAAVTFGTAIAAFYLPVIIMTVLYWHISRASKSRIKKDKKEPVANQDPVSPSLVQGRIVKPNNNNMPSSDDGLEHNKIQNGKAPRDPVTENCVQGEEKESSNDSTSVSAVASNMRDDEITQDENTVSTSLGHSKDENSKQTCIRIGTKTPKSDSCTPTNTTVEVVGSSGQNGDEKQNIVARKIVKMTKQPAKKKPPPSREKKVTRTILAILLAFIITWAPYNVMVLINTFCAPCIPNTVWTIGYWLCYINSTINPACYALCNATFKKTFKHLLMCHYKNIGATR', 'MTLHNNSTTSPLFPNISSSWIHSPSDAGLPPGTVTHFGSYNVSRAAGNFSSPDGTTDDPLGGHTVWQVVFIAFLTGILALVTIIGNILVIVSFKVNKQLKTVNNYFLLSLACADLIIGVISMNLFTTYIIMNRWALGNLACDLWLAIDYVASNASVMNLLVISFDRYFSITRPLTYRAKRTTKRAGVMIGLAWVISFVLWAPAILFWQYFVGKRTVPPGECFIQFLSEPTITFGTAIAAFYMPVTIMTILYWRIYKETEKRTKELAGLQASGTEAETENFVHPTGSSRSCSSYELQQQSMKRSNRRKYGRCHFWFTTKSWKPSSEQMDQDHSSSDSWNNNDAAASLENSASSDEEDIGSETRAIYSIVLKLPGHSTILNSTKLPSSDNLQVPEEELGMVDLERKADKLQAQKSVDDGGSFPKSFSKLPIQLESAVDTAKTSDVNSSVGKSTATLPLSFKEATLAKRFALKTRSQITKRKRMSLVKEKKAAQTLSAILLAFIITWTPYNIMVLVNTFCDSCIPKTFWNLGYWLCYINSTVNPVCYALCNKTFRTTFKMLLLCQCDKKKRRKQQYQQRQSVIFHKRAPEQAL', 'MGLRSHHLSLGLLLLFLLPAECLGAEGRLALKLFRDLFANYTSALRPVADTDQTLNVTLEVTLSQIIDMDERNQVLTLYLWIRQEWTDAYLRWDPNAYGGLDAIRIPSSLVWRPDIVLYNKADAQPPGSASTNVVLRHDGAVRWDAPAITRSSCRVDVAAFPFDAQHCGLTFGSWTHGGHQLDVRPRGAAASLADFVENVEWRVLGMPARRRVLTYGCCSEPYPDVTFTLLLRRRAAAYVCNLLLPCVLISLLAPLAFHLPADSGEKVSLGVTVLLALTVFQLLLAESMPPAESVPLIGKYYMATMTMVTFSTALTILIMNLHYCGPSVRPVPAWARALLLGHLARGLCVRERGEPCGQSRPPELSPSPQSPEGGAGPPAGPCHEPRCLCRQEALLHHVATIANTFRSHRAAQRCHEDWKRLARVMDRFFLAIFFSMALVMSLLVLVQAL', 'MNWSHSCISFCWIYFAASRLRAAETADGKYAQKLFNDLFEDYSNALRPVEDTDKVLNVTLQITLSQIKDMDERNQILTAYLWIRQIWHDAYLTWDRDQYDGLDSIRIPSDLVWRPDIVLYNKADDESSEPVNTNVVLRYDGLITWDAPAITKSSCVVDVTYFPFDNQQCNLTFGSWTYNGNQVDIFNALDSGDLSDFIEDVEWEVHGMPAVKNVISYGCCSEPYPDVTFTLLLKRRSSFYIVNLLIPCVLISFLAPLSFYLPAASGEKVSLGVTILLAMTVFQLMVAEIMPASENVPLIGKYYIATMALITASTALTIMVMNIHFCGAEARPVPHWARVVILKYMSRVLFVYDVGESCLSPHHSRERDHLTKVYSKLPESNLKAARNKDLSRKKDMNKRLKNDLGCQGKNPQEAESYCAQYKVLTRNIEYIAKCLKDHKATNSKGSEWKKVAKVIDRFFMWIFFIMVFVMTILIIARAD', 'MRCSPGGVWLALAASLLHVSLQGEFQRKLYKELVKNYNPLERPVANDSQPLTVYFSLSLLQIMDVDEKNQVLTTNIWLQMSWTDHYLQWNVSEYPGVKTVRFPDGQIWKPDILLYNSADERFDATFHTNVLVNSSGHCQYLPPGIFKSSCYIDVRWFPFDVQHCKLKFGSWSYGGWSLDLQMQEADISGYIPNGEWDLVGIPGKRSERFYECCKEPYPDVTFTVTMRRRTLYYGLNLLIPCVLISALALLVFLLPADSGEKISLGITVLLSLTVFMLLVAEIMPATSDSVPLIAQYFASTMIIVGLSVVVTVIVLQYHHHDPDGGKMPKWTRVILLNWCAWFLRMKRPGEDKVRPACQHKQRRCSLASVEMSAVAPPPASNGNLLYIGFRGLDGVHCVPTPDSGVVCGRMACSPTHDEHLLHGGQPPEGDPDLAKILEEVRYIANRFRCQDESEAVCSEWKFAACVVDRLCLMAFSVFTIICTIGILMSAPNFVEAVSKDFA', 'MGSGPLSLPLALSPPRLLLLLLLSLLPVARASEAEHRLFERLFEDYNEIIRPVANVSDPVIIHFEVSMSQLVKVDEVNQIMETNLWLKQIWNDYKLKWNPSDYGGAEFMRVPAQKIWKPDIVLYNNAVGDFQVDDKTKALLKYTGEVTWIPPAIFKSSCKIDVTYFPFDYQNCTMKFGSWSYDKAKIDLVLIGSSMNLKDYWESGEWAIIKAPGYKHDIKYNCCEEIYPDITYSLYIRRLPLFYTINLIIPCLLISFLTVLVFYLPSDCGEKVTLCISVLLSLTVFLLVITETIPSTSLVIPLIGEYLLFTMIFVTLSIVITVFVLNVHYRTPTTHTMPSWVKTVFLNLLPRVMFMTRPTSNEGNAQKPRPLYGAELSNLNCFSRAESKGCKEGYPCQDGMCGYCHHRRIKISNFSANLTRSSSSESVDAVLSLSALSPEIKEAIQSVKYIAENMKAQNEAKEIQDDWKYVAMVIDRIFLWVFTLVCILGTAGLFLQPLMAREDA', 'MAARGSGPRALRLLLLVQLVAGRCGLAGAAGGAQRGLSEPSSIAKHEDSLLKDLFQDYERWVRPVEHLNDKIKIKFGLAISQLVDVDEKNQLMTTNVWLKQEWIDVKLRWNPDDYGGIKVIRVPSDSVWTPDIVLFDNADGRFEGTSTKTVIRYNGTVTWTPPANYKSSCTIDVTFFPFDLQNCSMKFGSWTYDGSQVDIILEDQDVDKRDFFDNGEWEIVSATGSKGNRTDSCCWYPYVTYSFVIKRLPLFYTLFLIIPCIGLSFLTVLVFYLPSNEGEKICLCTSVLVSLTVFLLVIEEIIPSSSKVIPLIGEYLVFTMIFVTLSIMVTVFAINIHHRSSSTHNAMAPLVRKIFLHTLPKLLCMRSHVDRYFTQKEETESGSGPKSSRNTLEAALDSIRYITRHIMKENDVREVVEDWKFIAQVLDRMFLWTFLFVSIVGSLGLFVPVIYKWANILIPVHIGNANK', 'MALVRALVCCLLTAWHCRSGLGLPVAPAGGRNPPPAIGQFWHVTDLHLDPTYHITDDHTKVCASSKGANASNPGPFGDVLCDSPYQLILSAFDFIKNSGQEASFMIWTGDSPPHVPVPELSTDTVINVITNMTTTIQSLFPNLQVFPALGNHDYWPQDQLPVVTSKVYNAVANLWKPWLDEEAISTLRKGGFYSQKVTTNPNLRIISLNTNLYYGPNIMTLNKTDPANQFEWLESTLNNSQQNKEKVYIIAHVPVGYLPSSQNITAMREYYNEKLIDIFQKYSDVIAGQFYGHTHRDSIMVLSDKKGSPVNSLFVAPAVTPVKSVLEKQTNNPGIRLFQYDPRDYKLLDMLQYYLNLTEANLKGESIWKLEYILTQTYDIEDLQPESLYGLAKQFTILDSKQFIKYYNYFFVSYDSSVTCDKTCKAFQICAIMNLDNISYADCLKQLYIKHNY', 'MTKREAEELIEIEIDGTEKAECTEESIVEQTYAPAECVSQAIDINEPIGNLKKLLEPRLQCSLDAHEICLQDIQLDPERSLFDQGVKTDGTVQLSVQVISYQGIEPKLNILEIVKPADTVEVVIDPDAHHAESEAHLVEEAQVITLDGTKHITTISDETSEQVTRWAAALEGYRKEQERLGIPYDPIQWSTDQVLHWVVWVMKEFSMTDIDLTTLNISGRELCSLNQEDFFQRVPRGEILWSHLELLRKYVLASQEQQMNEIVTIDQPVQIIPASVQSATPTTIKVINSSAKAAKVQRAPRISGEDRSSPGNRTGNNGQIQLWQFLLELLTDKDARDCISWVGDEGEFKLNQPELVAQKWGQRKNKPTMNYEKLSRALRYYYDGDMICKVQGKRFVYKFVCDLKTLIGYSAAELNRLVTECEQKKLAKMQLHGIAQPVTAVALATASLQTEKDN', 'MSLPNSSCLLEDKMCEGNKTTMASPQLMPLVVVLSTICLVTVGLNLLVLYAVRSERKLHTVGNLYIVSLSVADLIVGAVVMPMNILYLLMSKWSLGRPLCLFWLSMDYVASTASIFSVFILCIDRYRSVQQPLRYLKYRTKTRASATILGAWFLSFLWVIPILGWNHFMQQTSVRREDKCETDFYDVTWFKVMTAIINFYLPTLLMLWFYAKIYKAVRQHCQHRELINRSLPSFSEIKLRPENPKGDAKKPGKESPWEVLKRKPKDAGGGSVLKSPSQTPKEMKSPVVFSQEDDREVDKLYCFPLDIVHMQAAAEGSSRDYVAVNRSHGQLKTDEQGLNTHGASEISEDQMLGDSQSFSRTDSDTTTETAPGKGKLRSGSNTGLDYIKFTWKRLRSHSRQYVSGLHMNRERKAAKQLGFIMAAFILCWIPYFIFFMVIAFCKNCCNEHLHMFTIWLGYINSTLNPLIYPLCNENFKKTFKRILHIRS', 'MDQNQHLNKTAEAQPSENKKTRYCNGLKMFLAALSLSFIAKTLGAIIMKSSIIHIERRFEISSSLVGFIDGSFEIGNLLVIVFVSYFGSKLHRPKLIGIGCFIMGIGGVLTALPHFFMGYYRYSKETNINSSENSTSTLSTCLINQILSLNRASPEIVGKGCLKESGSYMWIYVFMGNMLRGIGETPIVPLGLSYIDDFAKEGHSSLYLGILNAIAMIGPIIGFTLGSLFSKMYVDIGYVDLSTIRITPTDSRWVGAWWLNFLVSGLFSIISSIPFFFLPQTPNKPQKERKASLSLHVLETNDEKDQTANLTNQGKNITKNVTGFFQSFKSILTNPLYVMFVLLTLLQVSSYIGAFTYVFKYVEQQYGQPSSKANILLGVITIPIFASGMFLGGYIIKKFKLNTVGIAKFSCFTAVMSLSFYLLYFFILCENKSVAGLTMTYDGNNPVTSHRDVPLSYCNSDCNCDESQWEPVCGNNGITYISPCLAGCKSSSGNKKPIVFYNCSCLEVTGLQNRNYSAHLGECPRDDACTRKFYFFVAIQVLNLFFSALGGTSHVMLIVKIVQPELKSLALGFHSMVIRALGGILAPIYFGALIDTTCIKWSTNNCGTRGSCRTYNSTSFSRVYLGLSSMLRVSSLVLYIILIYAMKKKYQEKDINASENGSVMDEANLESLNKNKHFVPSAGADSETHC', None, 'MGPRIGPAGEVPQVPDKETKATMGTENTPGGKASPDPQDVRPSVFHNIKLFVLCHSLLQLAQLMISGYLKSSISTVEKRFGLSSQTSGLLASFNEVGNTALIVFVSYFGSRVHRPRMIGYGAILVALAGLLMTLPHFISEPYRYDNTSPEDMPQDFKASLCLPTTSAPASAPSNGNCSSYTETQHLSVVGIMFVAQTLLGVGGVPIQPFGISYIDDFAHNSNSPLYLGILFAVTMMGPGLAFGLGSLMLRLYVDINQMPEGGISLTIKDPRWVGAWWLGFLIAAGAVALAAIPYFFFPKEMPKEKRELQFRRKVLAVTDSPARKGKDSPSKQSPGESTKKQDGLVQIAPNLTVIQFIKVFPRVLLQTLRHPIFLLVVLSQVCLSSMAAGMATFLPKFLERQFSITASYANLLIGCLSFPSVIVGIVVGGVLVKRLHLGPVGCGALCLLGMLLCLFFSLPLFFIGCSSHQIAGITHQTSAHPGLELSPSCMEACSCPLDGFNPVCDPSTRVEYITPCHAGCSSWVVQDALDNSQVFYTNCSCVVEGNPVLAGSCDSTCSHLVVPFLLLVSLGSALACLTHTPSFMLILRGVKKEDKTLAVGIQFMFLRILAWMPSPVIHGSAIDTTCVHWALSCGRRAVCRYYNNDLLRNRFIGLQFFFKTGSVICFALVLAVLRQQDKEARTKESRSSPAVEQQLLVSGPGKKPEDSRV']\n",
      "52\n"
     ]
    }
   ],
   "source": [
    "sequences = [p.seq if p is not None else None for p in proteins.values()]\n",
    "print(sequences)\n",
    "print(len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df['sequence'] = sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name2_entry</th>\n",
       "      <th>human_uniprot_id</th>\n",
       "      <th>mouse_uniprot_id</th>\n",
       "      <th>rat_uniprot_id</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CYP1A2</td>\n",
       "      <td>P05177</td>\n",
       "      <td>P00186</td>\n",
       "      <td>P04799</td>\n",
       "      <td>MALSQSVPFSATELLLASAIFCLVFWVLKGLRPRVPKGLKSPPEPW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CYP2B6</td>\n",
       "      <td>P20813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MELSVLLFLALLTGLLLLLVQRHPNTHDRLPPGPRPLPLLGNLLQM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CYP2C9</td>\n",
       "      <td>P11712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MDSLVVLVLCLSCLLLLSLWRQSSGRGKLPPGPTPLPVIGNILQIG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CYP2C19</td>\n",
       "      <td>P33261</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MDPFVVLVLCLSCLLLLSIWRQSSGRGKLPPGPTPLPVIGNILQID...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CYP2D6</td>\n",
       "      <td>P10635</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  name2_entry human_uniprot_id mouse_uniprot_id rat_uniprot_id  \\\n",
       "0      CYP1A2           P05177           P00186         P04799   \n",
       "1      CYP2B6           P20813              NaN            NaN   \n",
       "2      CYP2C9           P11712              NaN            NaN   \n",
       "3     CYP2C19           P33261              NaN            NaN   \n",
       "4      CYP2D6           P10635              NaN            NaN   \n",
       "\n",
       "                                            sequence  \n",
       "0  MALSQSVPFSATELLLASAIFCLVFWVLKGLRPRVPKGLKSPPEPW...  \n",
       "1  MELSVLLFLALLTGLLLLLVQRHPNTHDRLPPGPRPLPLLGNLLQM...  \n",
       "2  MDSLVVLVLCLSCLLLLSLWRQSSGRGKLPPGPTPLPVIGNILQIG...  \n",
       "3  MDPFVVLVLCLSCLLLLSIWRQSSGRGKLPPGPTPLPVIGNILQID...  \n",
       "4  MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name2_entry</th>\n",
       "      <th>human_uniprot_id</th>\n",
       "      <th>mouse_uniprot_id</th>\n",
       "      <th>rat_uniprot_id</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>SMPDL3A</td>\n",
       "      <td>Q92484</td>\n",
       "      <td>P70158</td>\n",
       "      <td>Q641Z7</td>\n",
       "      <td>MALVRALVCCLLTAWHCRSGLGLPVAPAGGRNPPPAIGQFWHVTDL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>GABPA</td>\n",
       "      <td>Q06546</td>\n",
       "      <td>Q00422</td>\n",
       "      <td>A0A8I6GML2</td>\n",
       "      <td>MTKREAEELIEIEIDGTEKAECTEESIVEQTYAPAECVSQAIDINE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>HRH1</td>\n",
       "      <td>P35367</td>\n",
       "      <td>P70174</td>\n",
       "      <td>P31390</td>\n",
       "      <td>MSLPNSSCLLEDKMCEGNKTTMASPQLMPLVVVLSTICLVTVGLNL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>SLCO1B1</td>\n",
       "      <td>Q9Y6L6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MDQNQHLNKTAEAQPSENKKTRYCNGLKMFLAALSLSFIAKTLGAI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>SLCO2B1</td>\n",
       "      <td>O94956</td>\n",
       "      <td>Q8BXB6</td>\n",
       "      <td>Q9JHI3</td>\n",
       "      <td>MGPRIGPAGEVPQVPDKETKATMGTENTPGGKASPDPQDVRPSVFH...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name2_entry human_uniprot_id mouse_uniprot_id rat_uniprot_id  \\\n",
       "46     SMPDL3A           Q92484           P70158         Q641Z7   \n",
       "47       GABPA           Q06546           Q00422     A0A8I6GML2   \n",
       "48        HRH1           P35367           P70174         P31390   \n",
       "49     SLCO1B1           Q9Y6L6              NaN            NaN   \n",
       "51     SLCO2B1           O94956           Q8BXB6         Q9JHI3   \n",
       "\n",
       "                                             sequence  \n",
       "46  MALVRALVCCLLTAWHCRSGLGLPVAPAGGRNPPPAIGQFWHVTDL...  \n",
       "47  MTKREAEELIEIEIDGTEKAECTEESIVEQTYAPAECVSQAIDINE...  \n",
       "48  MSLPNSSCLLEDKMCEGNKTTMASPQLMPLVVVLSTICLVTVGLNL...  \n",
       "49  MDQNQHLNKTAEAQPSENKKTRYCNGLKMFLAALSLSFIAKTLGAI...  \n",
       "51  MGPRIGPAGEVPQVPDKETKATMGTENTPGGKASPDPQDVRPSVFH...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_df.tail()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import esm\n",
    "import time\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Optional: Suppress a common warning from a specific ESM version about a deprecated function\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='esm.pretrained')\n",
    "\n",
    "def get_esm_embeddings(protein_sequences, model_name=\"esm2_t33_650M_UR50D\", \n",
    "                       repr_layer=None, include_bos_eos=False,\n",
    "                       truncation_seq_length=None, device=None):\n",
    "    \"\"\"\n",
    "    Extracts protein embeddings using an ESM model.\n",
    "\n",
    "    Args:\n",
    "        protein_sequences (list of str or str): A list of protein sequences (e.g., [\"MKTV...\", \"MSK...\"])\n",
    "                                                 or a single protein sequence string.\n",
    "        model_name (str): Name of the ESM model to use.\n",
    "                          Examples: \"esm2_t6_8M_UR50D\", \"esm2_t12_35M_UR50D\",\n",
    "                                    \"esm2_t30_150M_UR50D\", \"esm2_t33_650M_UR50D\",\n",
    "                                    \"esm1b_t33_650M_UR50S\" (ESM-1b)\n",
    "        repr_layer (int, optional): The layer from which to extract representations.\n",
    "                                    If None, defaults to the last layer.\n",
    "        include_bos_eos (bool): Whether to include the embeddings for BOS (Beginning Of Sequence)\n",
    "                                and EOS (End Of Sequence) tokens in per-residue embeddings.\n",
    "                                For sequence-level embeddings, these are typically excluded before averaging.\n",
    "        truncation_seq_length (int, optional): If set, sequences longer than this will be truncated.\n",
    "                                               The ESM models have a context window (e.g., 1024 for ESM-1b,\n",
    "                                               ESM-2 can often handle longer based on memory).\n",
    "                                               If None, no explicit truncation by this function, but model\n",
    "                                               might have its own limits.\n",
    "        device (str, optional): \"cuda\" for GPU, \"cpu\" for CPU. If None, autodetects.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with keys:\n",
    "            'per_residue_embeddings' (list of np.ndarray):\n",
    "                List of per-residue embeddings. Each element is a NumPy array of shape\n",
    "                (seq_len, embedding_dim). seq_len depends on `include_bos_eos`.\n",
    "            'sequence_embeddings' (list of np.ndarray):\n",
    "                List of sequence-level embeddings (mean-pooled over residues).\n",
    "                Each element is a NumPy array of shape (embedding_dim,).\n",
    "            'model_name' (str): The name of the model used.\n",
    "            'representation_layer' (int): The layer number from which embeddings were extracted.\n",
    "    \"\"\"\n",
    "    if isinstance(protein_sequences, str):\n",
    "        protein_sequences = [protein_sequences]\n",
    "\n",
    "    if device is None:\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Load ESM model\n",
    "    try:\n",
    "        model, alphabet = esm.pretrained.load_model_and_alphabet(model_name)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model {model_name}. Available models from esm.pretrained.ESM_PRETRAINED_MODEL_WEIGHTS:\")\n",
    "        # print(esm.pretrained.ESM_PRETRAINED_MODEL_WEIGHTS) # Might be too verbose\n",
    "        print(f\"Common choices: esm2_t33_650M_UR50D, esm1b_t33_650M_UR50S, esm2_t6_8M_UR50D\")\n",
    "        raise e\n",
    "\n",
    "    model = model.to(device)\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    if repr_layer is None:\n",
    "        repr_layer = model.num_layers # Default to the last layer\n",
    "    \n",
    "    print(f\"Extracting embeddings from layer: {repr_layer}\")\n",
    "    print(f\"Model has {model.num_layers} layers and embedding dimension {model.embed_dim}.\")\n",
    "\n",
    "\n",
    "    batch_converter = alphabet.get_batch_converter()\n",
    "\n",
    "    per_residue_embeddings_list = []\n",
    "    sequence_embeddings_list = []\n",
    "\n",
    "    # Prepare data for batching\n",
    "    # The batch_converter expects a list of tuples (name, sequence)\n",
    "    data_for_batching = []\n",
    "    for i, seq in enumerate(protein_sequences):\n",
    "        seq_id = f\"protein_{i+1}\"\n",
    "        if truncation_seq_length is not None and len(seq) > truncation_seq_length:\n",
    "            print(f\"Warning: Sequence {seq_id} (length {len(seq)}) is longer than truncation_seq_length ({truncation_seq_length}). Truncating.\")\n",
    "            seq = seq[:truncation_seq_length]\n",
    "        data_for_batching.append((seq_id, seq))\n",
    "    \n",
    "    # Batch conversion\n",
    "    # This adds BOS and EOS tokens, and handles padding for sequences of different lengths in a batch\n",
    "    batch_labels, batch_strs, batch_tokens = batch_converter(data_for_batching)\n",
    "    batch_tokens = batch_tokens.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Extract per-residue representations\n",
    "        # `results` is a dictionary with various outputs\n",
    "        results = model(batch_tokens, repr_layers=[repr_layer], return_contacts=False)\n",
    "        \n",
    "        # token_representations shape: (batch_size, seq_len_with_bos_eos, embed_dim)\n",
    "        token_representations = results[\"representations\"][repr_layer]\n",
    "\n",
    "    # Process each sequence in the batch\n",
    "    for i, protein_seq_str in enumerate(batch_strs):\n",
    "        # token_repr shape: (seq_len_with_bos_eos, embed_dim)\n",
    "        token_repr = token_representations[i] \n",
    "\n",
    "        # Per-residue embeddings\n",
    "        if include_bos_eos:\n",
    "            # Includes BOS and EOS tokens\n",
    "            per_residue_emb = token_repr.cpu().numpy()\n",
    "        else:\n",
    "            # Exclude BOS and EOS token embeddings\n",
    "            # BOS is at index 0, EOS is at len(protein_seq_str) + 1\n",
    "            per_residue_emb = token_repr[1 : len(protein_seq_str) + 1].cpu().numpy()\n",
    "        per_residue_embeddings_list.append(per_residue_emb)\n",
    "\n",
    "        # Sequence-level embedding (mean pooling over actual residues)\n",
    "        # We use token_repr[1 : len(protein_seq_str) + 1] to average only over actual amino acid residues\n",
    "        sequence_emb = token_repr[1 : len(protein_seq_str) + 1].mean(0).cpu().numpy()\n",
    "        sequence_embeddings_list.append(sequence_emb)\n",
    "        \n",
    "    return {\n",
    "        \"per_residue_embeddings\": per_residue_embeddings_list,\n",
    "        \"sequence_embeddings\": sequence_embeddings_list,\n",
    "        \"model_name\": model_name,\n",
    "        \"representation_layer\": repr_layer\n",
    "    }\n",
    "\n",
    "# --- Example Usage ---\n",
    "def process_sequence(seq, model_name=\"esm2_t12_35M_UR50D\", repr_layer=12, include_bos_eos=False):\n",
    "    print(\"--- Processing a list of sequences with default ESM-2 model ---\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(\"\\n--- Example with GPU (if available) and larger ESM-2 model ---\")\n",
    "    if torch.cuda.is_available():\n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            embeddings_data_gpu = get_esm_embeddings(\n",
    "                seq, # Just one sequence for quicker GPU demo\n",
    "                model_name=\"esm2_t33_650M_UR50D\", # Larger model\n",
    "                # repr_layer will default to last layer (33)\n",
    "                device=\"cuda\"\n",
    "            )\n",
    "            end_time = time.time()\n",
    "            print(f\"Time taken on GPU: {end_time - start_time:.2f} seconds\")\n",
    "            print(f\"Model used: {embeddings_data_gpu['model_name']}\")\n",
    "            print(f\"Representation layer: {embeddings_data_gpu['representation_layer']}\")\n",
    "            per_res_emb_g = embeddings_data_gpu[\"per_residue_embeddings\"][0]\n",
    "            seq_emb_g = embeddings_data_gpu[\"sequence_embeddings\"][0]\n",
    "            print(f\"  Per-residue embedding shape: {per_res_emb_g.shape}\")\n",
    "            print(f\"  Sequence embedding shape: {seq_emb_g.shape}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during GPU processing: {e}\")\n",
    "    else:\n",
    "        print(\"CUDA (GPU) not available. Skipping GPU example.\")\n",
    "\n",
    "    return seq_emb_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop SLC\n",
    "# print(target_df.loc[50])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t33_650M_UR50D.pt\" to /home/serramelendezcsm/.cache/torch/hub/checkpoints/esm2_t33_650M_UR50D.pt\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/regression/esm2_t33_650M_UR50D-contact-regression.pt\" to /home/serramelendezcsm/.cache/torch/hub/checkpoints/esm2_t33_650M_UR50D-contact-regression.pt\n",
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 100.06 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (516, 1280)\n",
      "  Sequence embedding shape: (1280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:40, 100.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [01:44, 43.57s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.99 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (491, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [01:47, 25.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.44 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (490, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [01:51, 16.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.61 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (490, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [01:55, 12.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.89 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (497, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [01:58,  9.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.39 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (503, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [02:01,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.46 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (1338, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [02:05,  6.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.45 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (1333, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [02:08,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.41 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (527, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [02:12,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.39 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (520, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [02:15,  4.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.37 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (501, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [02:18,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.36 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (375, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [02:22,  3.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.36 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (292, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [02:25,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.36 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (331, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [02:28,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.36 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (532, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [02:32,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.39 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (848, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [02:35,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.36 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (352, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [02:39,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.36 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (434, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [02:42,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.36 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (295, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [02:45,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.35 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (222, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [02:49,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.48 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (435, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [02:52,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.35 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (201, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [02:56,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.46 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (1159, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [02:59,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.55 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (2016, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [03:03,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.39 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (598, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [03:06,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.37 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (178, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [03:09,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.37 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (481, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [03:13,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.39 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (630, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n",
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29it [03:16,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken on GPU: 3.58 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (2240, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [03:20,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.39 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (620, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [03:23,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.40 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (617, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [03:26,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.37 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (227, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33it [03:30,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.40 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (572, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34it [03:33,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.38 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (465, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [03:37,  3.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.37 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (477, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36it [03:40,  3.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.37 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (413, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "37it [03:43,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.38 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (164, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "38it [03:47,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.37 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (360, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "39it [03:50,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.38 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (460, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [03:53,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.39 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (466, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41it [03:57,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.50 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (590, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42it [04:00,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.38 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (450, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43it [04:04,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.37 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (479, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [04:07,  3.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.38 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (502, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [04:10,  3.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.37 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (505, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "46it [04:14,  3.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.39 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (468, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "47it [04:17,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.37 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (453, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [04:21,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.38 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (454, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49it [04:24,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.38 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (487, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [04:27,  3.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.39 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (691, 1280)\n",
      "  Sequence embedding shape: (1280,)\n",
      "--- Processing a list of sequences with default ESM-2 model ---\n",
      "\n",
      "--- Example with GPU (if available) and larger ESM-2 model ---\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "51it [04:31,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings from layer: 33\n",
      "Model has 33 layers and embedding dimension 1280.\n",
      "Time taken on GPU: 3.39 seconds\n",
      "Model used: esm2_t33_650M_UR50D\n",
      "Representation layer: 33\n",
      "  Per-residue embedding shape: (709, 1280)\n",
      "  Sequence embedding shape: (1280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Import tqdm for displaying progress bars during iteration\n",
    "from tqdm import tqdm\n",
    "emb_dict = {}\n",
    "\n",
    "for i, row in tqdm(target_df.iterrows()):\n",
    "\n",
    "    pid = i\n",
    "    seq = row['sequence']\n",
    "    if seq is None:\n",
    "        print(f\"Skipping {pid} due to missing sequence.\")\n",
    "        continue\n",
    "    emb = process_sequence(seq)\n",
    "    emb_dict[pid] = emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('pcmol_targets.txt', 'r') as f:\n",
    "#    pcmol_targets = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of targets: 51, Length of Pcmol targets: 0\n",
      "Overlap between current and Pcmol targets: 0\n"
     ]
    }
   ],
   "source": [
    "## Check overlap between serra and pcmol targets\n",
    "#targets_set = set(target_df['human_uniprot_id'].tolist())\n",
    "#pcmol_targets_set = set([line.strip() for line in pcmol_targets])\n",
    "#overlap = targets_set.intersection(pcmol_targets_set)\n",
    "#print(f'Length of targets: {len(targets_set)}, Length of Pcmol targets: {len(pcmol_targets_set)}')\n",
    "#print(f\"Overlap between current and Pcmol targets: {len(overlap)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of targets: 51, Length of Pcmol targets: 0\n",
      "Overlap between current and Pcmol targets: 0\n"
     ]
    }
   ],
   "source": [
    "## Check overlap between serra and pcmol targets\n",
    "#targets_set = set(target_df['human_uniprot_id'].tolist())\n",
    "#pcmol_targets_set = set([line.strip() for line in pcmol_targets])\n",
    "#overlap = targets_set.intersection(pcmol_targets_set)\n",
    "#print(f'Length of targets: {len(targets_set)}, Length of Pcmol targets: {len(pcmol_targets_set)}')\n",
    "#print(f\"Overlap between current and Pcmol targets: {len(overlap)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of targets: 51, Length of Pcmol targets: 0\n",
      "Overlap between current and Pcmol targets: 0\n"
     ]
    }
   ],
   "source": [
    "## Check overlap between serra and pcmol targets\n",
    "#targets_set = set(target_df['human_uniprot_id'].tolist())\n",
    "#pcmol_targets_set = set([line.strip() for line in pcmol_targets])\n",
    "#overlap = targets_set.intersection(pcmol_targets_set)\n",
    "#print(f'Length of targets: {len(targets_set)}, Length of Pcmol targets: {len(pcmol_targets_set)}')\n",
    "#print(f\"Overlap between current and Pcmol targets: {len(overlap)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_ids = np.array(list(emb_dict.keys()))\n",
    "embeddings = np.array(list(emb_dict.values()))\n",
    "np.save('embeddings.npy', embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df.to_csv('targets_w_sequences.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02037282, -0.09056199, -0.07410282, ..., -0.12021448,\n",
       "       -0.04532661,  0.11132984], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51, 1280)\n",
      "Original embedding shape: (51, 1280)\n",
      "Reduced embedding shape: (51, 2)\n",
      "Explained variance ratio: 0.545\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "# Convert dictionary to array for PCA\n",
    "embeddings_array = np.array(list(emb_dict.values()))\n",
    "print(embeddings_array.shape)\n",
    "# embeddings_array = embeddings_array.squeeze(1)\n",
    "\n",
    "# Initialize PCA with 256 components\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# Fit and transform the embeddings\n",
    "reduced_embeddings = pca.fit_transform(embeddings_array)\n",
    "\n",
    "# Create a dictionary mapping protein IDs to their reduced embeddings\n",
    "reduced_emb_dict = {pid: emb for pid, emb in zip(emb_dict.keys(), reduced_embeddings)}\n",
    "\n",
    "# Print some information about the dimensionality reduction\n",
    "print(f\"Original embedding shape: {embeddings_array.shape}\")\n",
    "print(f\"Reduced embedding shape: {reduced_embeddings.shape}\")\n",
    "print(f\"Explained variance ratio: {sum(pca.explained_variance_ratio_):.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name2_entry</th>\n",
       "      <th>human_uniprot_id</th>\n",
       "      <th>mouse_uniprot_id</th>\n",
       "      <th>rat_uniprot_id</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CYP1A2</td>\n",
       "      <td>P05177</td>\n",
       "      <td>P00186</td>\n",
       "      <td>P04799</td>\n",
       "      <td>MALSQSVPFSATELLLASAIFCLVFWVLKGLRPRVPKGLKSPPEPW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CYP2B6</td>\n",
       "      <td>P20813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MELSVLLFLALLTGLLLLLVQRHPNTHDRLPPGPRPLPLLGNLLQM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CYP2C9</td>\n",
       "      <td>P11712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MDSLVVLVLCLSCLLLLSLWRQSSGRGKLPPGPTPLPVIGNILQIG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CYP2C19</td>\n",
       "      <td>P33261</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MDPFVVLVLCLSCLLLLSIWRQSSGRGKLPPGPTPLPVIGNILQID...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CYP2D6</td>\n",
       "      <td>P10635</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  name2_entry human_uniprot_id mouse_uniprot_id rat_uniprot_id  \\\n",
       "0      CYP1A2           P05177           P00186         P04799   \n",
       "1      CYP2B6           P20813              NaN            NaN   \n",
       "2      CYP2C9           P11712              NaN            NaN   \n",
       "3     CYP2C19           P33261              NaN            NaN   \n",
       "4      CYP2D6           P10635              NaN            NaN   \n",
       "\n",
       "                                            sequence  \n",
       "0  MALSQSVPFSATELLLASAIFCLVFWVLKGLRPRVPKGLKSPPEPW...  \n",
       "1  MELSVLLFLALLTGLLLLLVQRHPNTHDRLPPGPRPLPLLGNLLQM...  \n",
       "2  MDSLVVLVLCLSCLLLLSLWRQSSGRGKLPPGPTPLPVIGNILQIG...  \n",
       "3  MDPFVVLVLCLSCLLLLSIWRQSSGRGKLPPGPTPLPVIGNILQID...  \n",
       "4  MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'papyrus_targets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpapyrus_targets\u001b[49m\u001b[38;5;241m.\u001b[39mhead() \n",
      "\u001b[0;31mNameError\u001b[0m: name 'papyrus_targets' is not defined"
     ]
    }
   ],
   "source": [
    "papyrus_targets.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'papyrus_targets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0m \u001b[43mpapyrus_targets\u001b[49m\u001b[38;5;241m.\u001b[39mhead() \n",
      "\n",
      "\u001b[0;31mNameError\u001b[0m: name 'papyrus_targets' is not defined"
     ]
    }
   ],
   "source": [
    "papyrus_targets.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'papyrus_targets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0m \u001b[43mpapyrus_targets\u001b[49m\u001b[38;5;241m.\u001b[39mhead() \n",
      "\n",
      "\u001b[0;31mNameError\u001b[0m: name 'papyrus_targets' is not defined"
     ]
    }
   ],
   "source": [
    "papyrus_targets.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02037282, -0.09056199, -0.07410282, ..., -0.12021448,\n",
       "       -0.04532661,  0.11132984], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'emb_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43memb_df\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'emb_df' is not defined"
     ]
    }
   ],
   "source": [
    "emb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['accession', 'UniProtID', 'mols_in_papyrus', 'mols_in_papyrus_pp',\n",
      "       'name', 'Status', 'Organism', 'Classification', 'Length', 'Sequence',\n",
      "       'TID', 'family', 'c1', 'c2', 'c3', 'c4', 'c5', 'c1_', 'c1_*', 'orphan'],\n",
      "      dtype='object')\n",
      "Index(['accession', 'UniProtID', 'mols_in_papyrus', 'mols_in_papyrus_pp',\n",
      "       'name', 'Status', 'Organism', 'Classification', 'Length', 'Sequence',\n",
      "       'TID', 'family', 'c1', 'c2', 'c3', 'c4', 'c5', 'c1_', 'c1_*', 'orphan'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on int64 and object columns for key 'accession'. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     21\u001b[39m targ_df = target_df.merge(papyrus_targets[[\u001b[33m'\u001b[39m\u001b[33maccession\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mc3\u001b[39m\u001b[33m'\u001b[39m]], on=\u001b[33m'\u001b[39m\u001b[33maccession\u001b[39m\u001b[33m'\u001b[39m, how=\u001b[33m'\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m## Remove NaN from pchembl_value_Meao\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m emb_df = \u001b[43memb_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarg_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43maccession\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mc3\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43maccession\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mleft\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/zfsdata/scratch/ollama/mm/envs/gnns/lib/python3.11/site-packages/pandas/core/frame.py:10832\u001b[39m, in \u001b[36mDataFrame.merge\u001b[39m\u001b[34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m  10813\u001b[39m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m  10814\u001b[39m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents=\u001b[32m2\u001b[39m)\n\u001b[32m  10815\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmerge\u001b[39m(\n\u001b[32m   (...)\u001b[39m\u001b[32m  10828\u001b[39m     validate: MergeValidate | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m  10829\u001b[39m ) -> DataFrame:\n\u001b[32m  10830\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mreshape\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmerge\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[32m> \u001b[39m\u001b[32m10832\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  10833\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m  10834\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10835\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10836\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10837\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10838\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10839\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10840\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10841\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10842\u001b[39m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m=\u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10843\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10844\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10845\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10846\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/zfsdata/scratch/ollama/mm/envs/gnns/lib/python3.11/site-packages/pandas/core/reshape/merge.py:170\u001b[39m, in \u001b[36mmerge\u001b[39m\u001b[34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m    155\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _cross_merge(\n\u001b[32m    156\u001b[39m         left_df,\n\u001b[32m    157\u001b[39m         right_df,\n\u001b[32m   (...)\u001b[39m\u001b[32m    167\u001b[39m         copy=copy,\n\u001b[32m    168\u001b[39m     )\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m     op = \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m=\u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m op.get_result(copy=copy)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/zfsdata/scratch/ollama/mm/envs/gnns/lib/python3.11/site-packages/pandas/core/reshape/merge.py:807\u001b[39m, in \u001b[36m_MergeOperation.__init__\u001b[39m\u001b[34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[39m\n\u001b[32m    803\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_tolerance(\u001b[38;5;28mself\u001b[39m.left_join_keys)\n\u001b[32m    805\u001b[39m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[32m    806\u001b[39m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m807\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_coerce_merge_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    809\u001b[39m \u001b[38;5;66;03m# If argument passed to validate,\u001b[39;00m\n\u001b[32m    810\u001b[39m \u001b[38;5;66;03m# check if columns specified as unique\u001b[39;00m\n\u001b[32m    811\u001b[39m \u001b[38;5;66;03m# are in fact unique.\u001b[39;00m\n\u001b[32m    812\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m validate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/zfsdata/scratch/ollama/mm/envs/gnns/lib/python3.11/site-packages/pandas/core/reshape/merge.py:1508\u001b[39m, in \u001b[36m_MergeOperation._maybe_coerce_merge_keys\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1502\u001b[39m     \u001b[38;5;66;03m# unless we are merging non-string-like with string-like\u001b[39;00m\n\u001b[32m   1503\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[32m   1504\u001b[39m         inferred_left \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_right \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[32m   1505\u001b[39m     ) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1506\u001b[39m         inferred_right \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_left \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[32m   1507\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1508\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m   1510\u001b[39m \u001b[38;5;66;03m# datetimelikes must match exactly\u001b[39;00m\n\u001b[32m   1511\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m needs_i8_conversion(lk.dtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m needs_i8_conversion(rk.dtype):\n",
      "\u001b[31mValueError\u001b[39m: You are trying to merge on int64 and object columns for key 'accession'. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "emb_df = pd.DataFrame(reduced_emb_dict)\n",
    "emb_df = emb_df.transpose()\n",
    "emb_df['accession']=emb_df.index\n",
    "emb_df['accession']=emb_df['accession'].astype(int)\n",
    "\n",
    "## Targets dataframe\n",
    "papyrus_targets = pd.read_csv('/home/andrius/datasets/molecules/subsets/all/targets.csv')\n",
    "## Rename target_id to accession\n",
    "target_df.rename(columns={'target_id': 'accession'}, inplace=True)\n",
    "print(targets.columns)\n",
    "## Add 'c3' column from targets to poses_grouped\n",
    "\n",
    "# klifs = pd.read_csv('klifs.csv')\n",
    "# print(klifs.columns)\n",
    "\n",
    "## Rename target_df.human_uniprot_id to accession\n",
    "target_df.rename(columns={'human_uniprot_id': 'accession'}, inplace=True)\n",
    "papyrus_targets.rename(columns={'target_id': 'accession'}, inplace=True)\n",
    "print(targets.columns)\n",
    "\n",
    "# targ_df = target_df.merge(papyrus_targets[['accession', 'c3']], on='accession', how='left')\n",
    "\n",
    "\n",
    "## Remove NaN from pchembl_value_Meao\n",
    "# \n",
    "# \n",
    "emb_df = emb_df.merge(targ_df, on='accession', how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not interpret value `c3` for `hue`. An entry with this name does not appear in `data`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      4\u001b[39m plt.figure(figsize=(\u001b[32m10\u001b[39m, \u001b[32m7\u001b[39m)) \u001b[38;5;66;03m# Adjust figure size for better legend placement if needed\u001b[39;00m\n\u001b[32m      6\u001b[39m sns.set_style(\u001b[33m'\u001b[39m\u001b[33mwhite\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43msns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscatterplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43memb_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mc3\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmarkers\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpalette\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtab20\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinewidth\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mk\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m plt.legend(bbox_to_anchor=(\u001b[32m1\u001b[39m,\u001b[32m1\u001b[39m), fontsize=\u001b[32m20\u001b[39m)\n\u001b[32m     11\u001b[39m plt.xlabel(\u001b[33m'\u001b[39m\u001b[33mPC1\u001b[39m\u001b[33m'\u001b[39m, fontweight=\u001b[33m'\u001b[39m\u001b[33mbold\u001b[39m\u001b[33m'\u001b[39m, fontsize=\u001b[32m20\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/zfsdata/scratch/ollama/mm/envs/gnns/lib/python3.11/site-packages/seaborn/relational.py:615\u001b[39m, in \u001b[36mscatterplot\u001b[39m\u001b[34m(data, x, y, hue, size, style, palette, hue_order, hue_norm, sizes, size_order, size_norm, markers, style_order, legend, ax, **kwargs)\u001b[39m\n\u001b[32m    606\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mscatterplot\u001b[39m(\n\u001b[32m    607\u001b[39m     data=\u001b[38;5;28;01mNone\u001b[39;00m, *,\n\u001b[32m    608\u001b[39m     x=\u001b[38;5;28;01mNone\u001b[39;00m, y=\u001b[38;5;28;01mNone\u001b[39;00m, hue=\u001b[38;5;28;01mNone\u001b[39;00m, size=\u001b[38;5;28;01mNone\u001b[39;00m, style=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    612\u001b[39m     **kwargs\n\u001b[32m    613\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m615\u001b[39m     p = \u001b[43m_ScatterPlotter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    616\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    617\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m=\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    618\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlegend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlegend\u001b[49m\n\u001b[32m    619\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    621\u001b[39m     p.map_hue(palette=palette, order=hue_order, norm=hue_norm)\n\u001b[32m    622\u001b[39m     p.map_size(sizes=sizes, order=size_order, norm=size_norm)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/zfsdata/scratch/ollama/mm/envs/gnns/lib/python3.11/site-packages/seaborn/relational.py:396\u001b[39m, in \u001b[36m_ScatterPlotter.__init__\u001b[39m\u001b[34m(self, data, variables, legend)\u001b[39m\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *, data=\u001b[38;5;28;01mNone\u001b[39;00m, variables={}, legend=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    388\u001b[39m \n\u001b[32m    389\u001b[39m     \u001b[38;5;66;03m# TODO this is messy, we want the mapping to be agnostic about\u001b[39;00m\n\u001b[32m    390\u001b[39m     \u001b[38;5;66;03m# the kind of plot to draw, but for the time being we need to set\u001b[39;00m\n\u001b[32m    391\u001b[39m     \u001b[38;5;66;03m# this information so the SizeMapping can use it\u001b[39;00m\n\u001b[32m    392\u001b[39m     \u001b[38;5;28mself\u001b[39m._default_size_range = (\n\u001b[32m    393\u001b[39m         np.r_[\u001b[32m.5\u001b[39m, \u001b[32m2\u001b[39m] * np.square(mpl.rcParams[\u001b[33m\"\u001b[39m\u001b[33mlines.markersize\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    394\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m396\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    398\u001b[39m     \u001b[38;5;28mself\u001b[39m.legend = legend\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/zfsdata/scratch/ollama/mm/envs/gnns/lib/python3.11/site-packages/seaborn/_base.py:634\u001b[39m, in \u001b[36mVectorPlotter.__init__\u001b[39m\u001b[34m(self, data, variables)\u001b[39m\n\u001b[32m    629\u001b[39m \u001b[38;5;66;03m# var_ordered is relevant only for categorical axis variables, and may\u001b[39;00m\n\u001b[32m    630\u001b[39m \u001b[38;5;66;03m# be better handled by an internal axis information object that tracks\u001b[39;00m\n\u001b[32m    631\u001b[39m \u001b[38;5;66;03m# such information and is set up by the scale_* methods. The analogous\u001b[39;00m\n\u001b[32m    632\u001b[39m \u001b[38;5;66;03m# information for numeric axes would be information about log scales.\u001b[39;00m\n\u001b[32m    633\u001b[39m \u001b[38;5;28mself\u001b[39m._var_ordered = {\u001b[33m\"\u001b[39m\u001b[33mx\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}  \u001b[38;5;66;03m# alt., used DefaultDict\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m634\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43massign_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    636\u001b[39m \u001b[38;5;66;03m# TODO Lots of tests assume that these are called to initialize the\u001b[39;00m\n\u001b[32m    637\u001b[39m \u001b[38;5;66;03m# mappings to default values on class initialization. I'd prefer to\u001b[39;00m\n\u001b[32m    638\u001b[39m \u001b[38;5;66;03m# move away from that and only have a mapping when explicitly called.\u001b[39;00m\n\u001b[32m    639\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mhue\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msize\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstyle\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/zfsdata/scratch/ollama/mm/envs/gnns/lib/python3.11/site-packages/seaborn/_base.py:679\u001b[39m, in \u001b[36mVectorPlotter.assign_variables\u001b[39m\u001b[34m(self, data, variables)\u001b[39m\n\u001b[32m    674\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    675\u001b[39m     \u001b[38;5;66;03m# When dealing with long-form input, use the newer PlotData\u001b[39;00m\n\u001b[32m    676\u001b[39m     \u001b[38;5;66;03m# object (internal but introduced for the objects interface)\u001b[39;00m\n\u001b[32m    677\u001b[39m     \u001b[38;5;66;03m# to centralize / standardize data consumption logic.\u001b[39;00m\n\u001b[32m    678\u001b[39m     \u001b[38;5;28mself\u001b[39m.input_format = \u001b[33m\"\u001b[39m\u001b[33mlong\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m679\u001b[39m     plot_data = \u001b[43mPlotData\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    680\u001b[39m     frame = plot_data.frame\n\u001b[32m    681\u001b[39m     names = plot_data.names\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/zfsdata/scratch/ollama/mm/envs/gnns/lib/python3.11/site-packages/seaborn/_core/data.py:58\u001b[39m, in \u001b[36mPlotData.__init__\u001b[39m\u001b[34m(self, data, variables)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     52\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     53\u001b[39m     data: DataSource,\n\u001b[32m     54\u001b[39m     variables: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, VariableSpec],\n\u001b[32m     55\u001b[39m ):\n\u001b[32m     57\u001b[39m     data = handle_data_source(data)\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     frame, names, ids = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_assign_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.frame = frame\n\u001b[32m     61\u001b[39m     \u001b[38;5;28mself\u001b[39m.names = names\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/zfsdata/scratch/ollama/mm/envs/gnns/lib/python3.11/site-packages/seaborn/_core/data.py:232\u001b[39m, in \u001b[36mPlotData._assign_variables\u001b[39m\u001b[34m(self, data, variables)\u001b[39m\n\u001b[32m    230\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    231\u001b[39m         err += \u001b[33m\"\u001b[39m\u001b[33mAn entry with this name does not appear in `data`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    235\u001b[39m \n\u001b[32m    236\u001b[39m     \u001b[38;5;66;03m# Otherwise, assume the value somehow represents data\u001b[39;00m\n\u001b[32m    237\u001b[39m \n\u001b[32m    238\u001b[39m     \u001b[38;5;66;03m# Ignore empty data structures\u001b[39;00m\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, Sized) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(val) == \u001b[32m0\u001b[39m:\n",
      "\u001b[31mValueError\u001b[39m: Could not interpret value `c3` for `hue`. An entry with this name does not appear in `data`."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "plt.figure(figsize=(10, 7)) # Adjust figure size for better legend placement if needed\n",
    "    \n",
    "sns.set_style('white')\n",
    "\n",
    "\n",
    "sns.scatterplot(data=emb_df, x=0, y=1, hue='c3', markers='', palette='tab20', linewidth=1, alpha=0.8, edgecolor='k', s=100)\n",
    "plt.legend(bbox_to_anchor=(1,1), fontsize=20)\n",
    "plt.xlabel('PC1', fontweight='bold', fontsize=20)\n",
    "plt.gca().spines['top'].set_visible(True)\n",
    "plt.gca().spines['right'].set_visible(True)\n",
    "plt.gca().spines['bottom'].set_visible(True)\n",
    "\n",
    "plt.gca().spines['left'].set_visible(True)\n",
    "plt.gca().spines['top'].set_linewidth(2)\n",
    "plt.gca().spines['right'].set_linewidth(2)\n",
    "plt.gca().spines['bottom'].set_linewidth(2)\n",
    "plt.gca().spines['left'].set_linewidth(2)\n",
    "\n",
    "plt.ylabel('PC2', fontweight='bold', fontsize=20)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'umap' has no attribute 'UMAP'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mumap\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maligned_umap\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mumap\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvalidation\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m umap_reducer = \u001b[43mumap\u001b[49m\u001b[43m.\u001b[49m\u001b[43mUMAP\u001b[49m(n_components=\u001b[32m2\u001b[39m, random_state=\u001b[32m42\u001b[39m, n_neighbors=\u001b[32m15\u001b[39m, min_dist=\u001b[32m0.1\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Perform UMAP on the 'embeddings' data\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Assuming 'embeddings' is a variable (e.g., NumPy array) containing the high-dimensional data\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# and 'emb_df' is the DataFrame used for the PCA plot, containing the 'c3' column.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m \n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Fit UMAP to the embeddings and transform the data\u001b[39;00m\n\u001b[32m     15\u001b[39m umap_results = umap_reducer.fit_transform(embeddings)\n",
      "\u001b[31mAttributeError\u001b[39m: module 'umap' has no attribute 'UMAP'"
     ]
    }
   ],
   "source": [
    "import umap\n",
    "import umap.aligned_umap\n",
    "import umap.validation\n",
    "\n",
    "umap_reducer = umap.UMAP(n_components=2, random_state=42, n_neighbors=15, min_dist=0.1)\n",
    "\n",
    "# Perform UMAP on the 'embeddings' data\n",
    "# Assuming 'embeddings' is a variable (e.g., NumPy array) containing the high-dimensional data\n",
    "# and 'emb_df' is the DataFrame used for the PCA plot, containing the 'c3' column.\n",
    "\n",
    "# Initialize UMAP. Using n_components=2 for a 2D plot.\n",
    "# random_state is for reproducibility. Other parameters like n_neighbors and min_dist can be tuned.\n",
    "\n",
    "# Fit UMAP to the embeddings and transform the data\n",
    "umap_results = umap_reducer.fit_transform(embeddings)\n",
    "\n",
    "# Create a pandas DataFrame with the UMAP results\n",
    "df_umap = pd.DataFrame(data=umap_results, columns=['UMAP1', 'UMAP2'])\n",
    "\n",
    "# Add the 'c3' column from the PCA plot's DataFrame for coloring\n",
    "# This assumes that the rows in 'embeddings' correspond to the rows in 'emb_df'\n",
    "df_umap['c3'] = emb_df['c3'].values\n",
    "\n",
    "# Create the scatter plot, similar to the PCA plot\n",
    "\n",
    "# sns.set_style('white') # Already set in the previous cell, but can be re-applied\n",
    "sns.scatterplot(data=df_umap, x='UMAP1', y='UMAP2', hue='c3', markers='o', palette='tab20')\n",
    "plt.legend(bbox_to_anchor=(1,1)) # Match PCA plot legend style\n",
    "plt.xlabel('UMAP1') # Label for UMAP\n",
    "plt.ylabel('UMAP2') # Label for UMAP\n",
    "\n",
    "# Apply similar spine styling as the PCA plot\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(True)\n",
    "ax.spines['right'].set_visible(True)\n",
    "ax.spines['bottom'].set_visible(True)\n",
    "ax.spines['left'].set_visible(True)\n",
    "ax.spines['top'].set_linewidth(2)\n",
    "ax.spines['right'].set_linewidth(2)\n",
    "ax.spines['bottom'].set_linewidth(2)\n",
    "ax.spines['left'].set_linewidth(2)\n",
    "\n",
    "# Apply similar tick styling (empty ticks) as the PCA plot\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
